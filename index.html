<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="for the dream">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="for the dream">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="for the dream">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>for the dream</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">for the dream</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/21/mysql/innodb机制详解三：B-树索引原理及应用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/21/mysql/innodb机制详解三：B-树索引原理及应用/" itemprop="url">innodb机制详解三：B+树索引原理及应用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-21T00:00:00+08:00">
                2017-10-21
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index">
                    <span itemprop="name">mysql</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="B-树索引概述"><a href="#B-树索引概述" class="headerlink" title="B+树索引概述"></a>B+树索引概述</h1><blockquote>
<p>需要注意的是，在内存中的B+树和在磁盘中是不同的，在内存中的B+树是一种数据结构对象，而在磁盘中的B+树索引是一连串的0101二进制，是我们实实在在能用UE等工具读取文件进行分析的。在内存中的B+树是不需要考虑节点分裂方向的，而在磁盘中还需要根据记录的插入情况的不同记录分裂点信息和分裂方向。不过一般情况下，我们可以认为这两者就是一样的，这种理解并不会影响我们对于sql的优化和索引的利用，而且会更容易理解，所以我们就借助B+树在磁盘中的数据存储来映射其在内存中的使用情况。</p>
</blockquote>
<p>索引对mysql来说的重要性绝对是不言而喻，如果能对索引理解的非常深刻的话，对于写出高性能sql帮助是极大的。</p>
<p>看过很多关于Mysql索引优化的文章，比如左前缀索引、like优化、or等等的，其实只要理解了innodb底层索引的实现，就很容易知道这些优化到底对不对，以及到底如何写sql才能利用好索引。不过很多情况下，由于mysql查询优化器会对我们写出的sql进行相关优化，而且不同版本的mysql对于同样的sql语句的优化也可能不同，比如mysql5.6版本新出的MRR。</p>
<p>所以对于sql执行的性能优化以及索引的利用，不仅要结合索引自身，还要根据mysql的版本以及查询优化器的优化等很多种情况进行综合考虑，所以对于sql进行优化(除了那种明显效率极低的语句)需要考虑多中情况，针对业务设计合适的索引，并进行相关测试才能得出一个比较满意的结果。</p>
<p>但是不管怎么说，如果能深入理解Innodb内部索引的实现原理，对于sql调优就能有更多的理论支撑，即使面对不同版本的查询优化器，也能做出相应的应对，以写出最合适的sql。</p>
<p>对于innodb来说，内部的索引绝大部分都是B+树索引，最常用以及对于程序员来说最需要掌握的也是B+树索引，所以本篇文章只针对B+树索引。</p>
<p>树是一种数据结构，我们常见的有二叉树、234树、红黑树等等，相对于线性结构来说，树这种结构对于增删改查的效率都是极高的，所以树这种数据结构被广泛应用到各种场景中，比如文件系统、数据库索引等等。我们可能更熟悉二叉树(以及二叉树的改进版AVL树)、红黑树等，这种数据结构在内存中进行搜索的效率也是极高的，算法复杂度都是O(logN)的，但是我们知道，比如二叉树，一个节点最多只能有2个子节点，就会导致树的高度会非常高。而数据库中的数据必然不可能全部都在内存中，数据是按一个个page存放在磁盘文件中的，如果innodb采用二叉树、红黑树这种高度非常高的树的话，每一次搜索，可能都需要进行一次磁盘IO，而且还是随机IO，当数据量比较大的时候，查询速度肯定会比较慢。</p>
<p>所以innodb内部索引主要采用的是B+树索引，这种树的特点就是高度非常小，一般2-4层，如果每行记录只有200字节的话，那么一个page将能存放很多条记录(B+树的每一个节点就是一个page)，那么4层的B+树足以容纳上亿条数据，而4层的B+树结构，如果是根据主键查询某条数据，只需要进行4次磁盘IO就能获取到全部数据，效率显然极高。</p>
<p>之所以B+树能将这么多数据保持在2-4层的高度，就是因为这种高效的数据结构特性决定的。B+树的实现比起普通的二叉树、红黑树要复杂很多很多，而且innodb采用的B+树还是改进版的支持高并发的，所以我觉得如果不是做数据库内核开发的人员，其他程序员没有必要完全弄懂innodb的B+树是如何实现的，只需要理解B+树这种数据结构的搜索、插入、删除以及节点合并和分裂即可。</p>
<p>关于B+树这种数据结构的实现，网上随处可见，我个人对B+树的理解也只是停留在B+树节点的搜索、插入、删除以及节点合并和页分裂而已，所以这里就不在本篇文章中写了。</p>
<h1 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a>聚集索引</h1><blockquote>
<p>innodb中，同是B+树索引，又分为两大类：聚集索引、辅助索引(二级索引)。这里需要注意的是本节中讲的数据存储是针对聚集索引，而对于辅助索引来说，内部存储的数据和聚集索引不同。</p>
</blockquote>
<p>innodb中每一张表都存在唯一的主键(即使用户不设置主键，innodb也会默认创建一个主键，但应该不会有谁不给表设置主键把)，而聚集索引就是以主键为key的索引，对于叶子节点，聚集索引中存放了整行数据，也就是(key,row)；对于非叶子节点，key依然为主键，而里面存放的是指向下一层的地址，也就是(key,pointer)。</p>
<p>由此可知，innodb引擎的表中，数据是和主键索引排序后存放在一起的，所以可以说对于innodb来说，数据页也是是索引页。</p>
<p>关于聚集索引在文件中的存储，依然通过<code>Mysql技术内幕：innodb存储引擎(第2版)</code>书中的一个例子来讲。</p>
<p>表结构和测试数据如下所示：<br><img src="/images/mysql/聚集索引测试数据.png" alt=""></p>
<p>可以看到一共插入了4条数据，每条数据的长度都大于7000字节，所以1个page内最多能存放2条数据，这样的话，插入4条数据必然会导致叶子节点分裂，也就是说必然会存在非叶子节点。我们知道，对于聚集索引来说，叶子节点就是实际的数据页，而非叶子节点里面存放的是数据的主键以及指向下一层对应page的指针。</p>
<p>关于数据页的详情，在上一篇博客中以及讲的非常详细了，这一节就只看非叶子节点的page数据具体在磁盘中是如何存储的。</p>
<p>想要分析非叶子节点在文件中的数据，就要在表空间文件中找到对应的page。由于一共有4条数据，所以必然只有1个非叶子节点，这个page的page header中PAGE_LEVEL=1。但是表空间文件这么大，想要根据PAGE_LEVEL=1去定位root页显然不现实。</p>
<p>我的看法是可以借助每个page内都有的infimun和supermum伪记录来进行第一次定位(比如在文件中搜索infimun的ASCII值)，这次会找到多个page，然后在infimun向前寻找page header中PAGE_LEVEL=1的page就是我们要找的root page。分析page header部分内如下图所示：<br><img src="/images/mysql/索引页的page header.png" alt=""></p>
<p>可以看到PAGE_LEVEL=1，并且PAGE_N_RECS=3表示当前page有3条数据。这里需要解释下，对于叶子节点(也就是数据页)中有多少条数据我们应该很容易理解，对于非叶子节点(也就是索引页)中到底有多少条数据呢？其实前面我们已经说了，非叶子节点中存放的是(key,pointer)，这个pointer指向的是下一层的page。而主键和pointer所占用的字节数肯定很少，也就是说每个非叶子节点中能容纳非常多的记录数。这也是B+树索引能保持在2-4层的原因。(需要注意的是并不是每条数据都在非叶子节点页中有记录与之对应，当前叶子节点所有的记录加起来都只在上层的非叶子节点中对应1条数据)。</p>
<p>本例子中在表空间文件内，索引的具体存在形式如下图所示：<br><img src="/images/mysql/聚集索引.png" alt=""></p>
<p>由于数据量太少，所以只有2层。page level=0的就是数据页，一共有3个。page level=1的就是索引页，一共有1个。索引页中有3条记录，分别指向了3个叶子节点。</p>
<p>所以当用户查找主键为4的数据的时候，先查找索引页，发现4&gt;3，所以去根据pointer=36找page序号=36的页并加载到缓冲池中，然后在当前页内根据page dictionary进行二分查找找到id=4的列。</p>
<p>理解了聚集索引的存储结构和特点之后，我们就理解了为什么基于主键的精确查找、范围查找、排序速度会这么快！</p>
<p>对于主键精确查找，最多只需要4次磁盘IO就能找到数据项；对于范围查找，根据非叶子节点就能很快的定位出需要查找的记录具体在哪些叶子节点中；对于基于主键排序就更不需要解释了，聚集索引本身就是根据主键进行排序的，而且叶子节点是采用双链表结构存储，所以当查询诸如<code>select * from table order by id desc limit 10</code>就会极快，基于主键排序后的叶子节点是双向链表，所以可以迅速定位到最后10条记录，完全不需要filesort。</p>
<h1 id="辅助索引"><a href="#辅助索引" class="headerlink" title="辅助索引"></a>辅助索引</h1><p>辅助索引也是我们日常数据库设计中必不可少的索引，聚集索引毕竟只有1个，大多数情况下我们要对一些列建立辅助索引来提升查询性能。而网上也看到过很多文章介绍如何利用辅助索引来优化sql的，其实只要理解了辅助索引在innodb底层是如何存储和实现的，就自然会对sql优化有一些心得。</p>
<p>和聚集索引不同的是，辅助索引的叶子节点中中除了key之外，并不包含整行的数据记录。前面我们以及详细讲过聚集索引的叶子节点和非叶子节点，现在学习辅助索引，我们显然也要清楚的知道辅助索引的叶子节点和非叶子节点具体存放了什么数据。</p>
<p>对于辅助索引来说，一张表可以存在多个，甚至可以对多个列进行联合辅助索引。而且辅助索引和数据是分开存储，辅助索引的建立并不会对原有数据页造成影响。</p>
<p>对于前面的例子中，列c建立了辅助索引。由于辅助索引中并没有存储整行数据，所以占空间很小，所以对于4条数据来说，1个辅助索引page就足够。</p>
<p>辅助索引和聚集所以的关系如下图所示：</p>
<p><img src="/images/mysql/辅助索引和聚集索引的关系.png" alt=""></p>
<p>分析表空间文件，可知辅助索引的叶子节点中存放的是键和主键，而非叶子节点中存放的是键和指向下层辅助索引页的指针，如下图所示：</p>
<p><img src="/images/mysql/辅助索引详情.png" alt=""></p>
<p>可以看到由于数据较少，所以只存在1个叶子节点。由于c列的数据是-1、-2、-3、-4，所以节点中的key就是图中所示的值，而value则存储的是对应的主键。</p>
<p>所以当用户要查找c=-3的数据时，假设强制使用辅助索引c来查找，则根据辅助索引c=-3找到对应的主键为3，然后再根据主键查找id=3的数据。</p>
<p>由此可知，基于辅助索引的查找，会首先找到对应的主键，然后再根据主键进行查找，速度自然会比直接根据主键查找要慢一些。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/20/mysql/innodb机制详解二：日志文件详解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/20/mysql/innodb机制详解二：日志文件详解/" itemprop="url">innodb机制详解二：存储结构及表空间详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-20T00:00:00+08:00">
                2017-10-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index">
                    <span itemprop="name">mysql</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>本文说的存储结构都是在磁盘文件中的存储结构，而不是内存中的对象数据结构。比如说页，在磁盘文件中的表现实际就是一串16KB的010101二进制，只不过我们知道不同位置的01分别代表的什么信息，比如有的代表了当前page的一些信息，有的代表了数据行记录。而这些对象比如说page，在内存中也是有对应的数据结构的，比如需要标识当前page是在LRU链表还是在Free链表，标识当前page是数据页还是索引页还是inserf buffer页等等。在内存中的对象和在文件中存储的二进制之间是有很大的相似性的，但也不能认为文件中存储的是内存的镜像，在innodb中是有专门的模块和方法进行这些对象在内存和文件中进行转换的，比如读取表空间文件中的page到内存中，比如刷新脏页到表空间文件中。对于page、row、区等内存对象和表空间中的物理存储格式的区别，我个人觉得我们只需要知道即可，我们只需要知道表空间文件中数据具体是如何存储的就已经足够使我们对innodb的原理有很深刻的认识了。</p>
</blockquote>
<h1 id="表空间文件"><a href="#表空间文件" class="headerlink" title="表空间文件"></a>表空间文件</h1><p>在磁盘中，innodb数据表是存放在数据目录下的，可以通过以下命令来查看数据目录路径<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like '%datadir%';</span><br><span class="line">+<span class="comment">---------------+-----------------+</span></span><br><span class="line">| Variable_name | Value           |</span><br><span class="line">+<span class="comment">---------------+-----------------+</span></span><br><span class="line">| datadir       | /var/lib/mysql/ |</span><br><span class="line">+<span class="comment">---------------+-----------------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure></p>
<p>在这个路径下面，每个数据库对应一个目录，假设有ygq这个数据库<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /var/lib/mysql/ygq</span><br><span class="line">ls</span><br><span class="line">db.opt  ts.frm  ts.ibd</span><br></pre></td></tr></table></figure></p>
<p>可以看到这个目录下有3个文件，db.opt是记录ygq这个数据库的一些信息的，ts.frm和ts.idb则对应了这个数据库中的innodb引擎数据表ts。其中frm文件存储了表结构信息，比如包含哪些字段等等。ts.idb则存储了这个表的数据以及索引等信息。</p>
<p>默认情况下，innodb所有数据表的数据和索引都存放在公共的一个表空间文件中(称为系统表空间文件或共享表空间，但表结构文件.frm依然是分开放在各自的数据库目录下)。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like '%innodb_data_file_path%';</span><br><span class="line">+<span class="comment">-----------------------+------------------------+</span></span><br><span class="line">| Variable_name         | Value                  |</span><br><span class="line">+<span class="comment">-----------------------+------------------------+</span></span><br><span class="line">| innodb_data_file_path | ibdata1:10M:autoextend |</span><br><span class="line">+<span class="comment">-----------------------+------------------------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure></p>
<p>表示会在%datadir%下面有一个初始为10M的ibdata1文件，作为共享表空间文件，并且文件大小自动增长。如果innodb_file_per_table=off，那么所有innodb表的数据和索引都会存放在这个共享表空间文件中。如果将innodb_file_per_table=on，那么会在当前数据库目录下为每个新建的innodb数据表新建自己的.idb文件(例如上面的ts.idb)，当然即使有了自己独立的表空间文件，并不是所有信息都存在自己表空间文件中，自己独立的表空间文件中只存放数据、索引、插入缓冲的bitmap等信息。</p>
<p>其他信息，比如undo信息、插入缓冲索引页、系统事务信息、double write buffer依然是存在共享表空间中。对于共享表空间中具体有什么内容，<code>Mysql技术内幕：innodb存储引擎(第2版)</code>书中对于表空间的描述非常清晰，如下图所示：<br><img src="/images/mysql/ibdata.png" alt=""></p>
<p>对于Innodb的存储结构，从小到大依次分为页、区、段、表空间。如下图所示：<br><img src="/images/mysql/存储结构.png" alt=""></p>
<p>对于段来说，innodb主要有数据段、索引段和回滚端。由于Innodb是索引组织表，数据是和主键索引存放在一起的，所以数据及索引，也即B+书的叶子节点。而索引段可以理解为其他二级索引，也即非叶子节点。</p>
<p>对于区来说，如果一个page为16K的话，那么一个区由64个page组成，一个区的大小为1M。不过对于一些新建立的小表而言，innodb做了一些优化。如果开启了innodb_file_per_table=on，新建一张innodb数据表，里面没有任何数据，可以看到默认大小是96K。理论上来说innodb创建表每次申请磁盘空间都是按区分配的，至少得1M大小把，为什么只有96K呢？</p>
<p>其实是因为初始时，对于每个段(包括leaf node segment和non-leaf node segment以及undo segment)来说，先按需分配32个碎片页，只有当这些碎片页用完之后，才会按区分配。这样做就可以对一些小表以及undo段来说，就可以节省很多磁盘空间。</p>
<p>对于每个独立的表空间文件，通过<code>Mysql技术内幕：innodb存储引擎(第2版)</code>书中的一个例子可以有个非常清晰的理性认识。如下图所示：<br><img src="/images/mysql/例子1.png" alt=""><br>图中t1表结构非常简单，一个自增主键id列，一个是普通的varchar(7000)列，连续向其中插入3条这样的数据，由于默认情况下mysql编码方式是latin1，也就是1个字符占1个字节，所以三条记录总大小已经大于16K了，所以一个page装不下，由于innodb数据是采用B+树存放的，所以就会造成页的分裂，所以由1个页分裂成了3个B Tree Node Page,其中一个是索引页(非叶子节点)，两个数据页(叶子节点)。</p>
<p>此时由于只使用了3个页，并没有将初始的32个碎片页使用完，所以此时表空间文件依然小于1M。如果此时再向其中插入61条数据，也即一共64条数据，需要34个页(33个数据页，1个索引页)，这样的话，就用超出了leaf node segment的32个碎片页，那么innodb就会一下子分配至少一个区的page。如下图所示：<br><img src="/images/mysql/例子2.png" alt=""><br>可以看到，此时表空间文件中一共有128个页，也即2个区。其中有34个BTree Node Page。</p>
<h1 id="页"><a href="#页" class="headerlink" title="页"></a>页</h1><p>页(page)是innodb中极其重要的一个概念，页是innodb读取和写入数据的最小单元。包括用户根据主键查询数据时，根据主键索引能极其迅速的定位到所查询的某条数据所在的page，但一个page(默认16K)中一般都存放了很多行记录，所以使用索引只能定位到某个page，如果想定位到这个page内具体的某行数据，就需要借助当前page的page dictionary进行二分查找(之所以能使用二分查找是因为即使在每个page中的不同行记录，也是依据主键索引排序的)，只不过每个page里面的数据量本身就不大，二分查找速度又比较快，而且是在内存中查找，所以这个时间可以几乎忽略不计。</p>
<p>关于页，我们第一印象是觉得页是存放数据的，但其实页的种类有很多种，页里面除了存放具体的行记录，还可能存放索引(非叶子节点页索引)、插入缓冲、undo信息等等，所以主要有以下几种类型的页(只列举了我比较熟悉的)：</p>
<ol>
<li>数据页(因为主键索引是和数据存放一起的，也可以称之为主键索引页，这些页里面存放的是行记录)</li>
<li>索引页(指二级索引页以及非叶子节点的索引页，这些页里面存放的不是行记录，而是索引信息)</li>
<li>undo页</li>
<li>insert buffer bitmap页</li>
<li>insert buffe 空闲列表页</li>
<li>事务页</li>
<li>BLOG页</li>
</ol>
<p>下面我们主要讲我们最关心的数据页。一个page默认大小16K(用户可以使用innodb_page_size参数修改)，对于数据页来说，占用页内空间最大的自然是用户存的数据，但每个数据页内，除了用户的数据之外还需要一些其他信息，比如标识当前页是哪种类型的页、标识该页属于哪个表空间以及在表空间的偏移量(相当于该页在文件系统中的“坐标”，innodb根据页的坐标将其读入内存转换成内存中的一个对象)。由于B+ Tree的叶子节点是双向链表结构，所以每一个page都必须有一个指针指向前后相邻的页。所以一个page的总体结构如下图所示：<br><img src="/images/mysql/page结构.png" alt=""></p>
<p>更详细的page结构如下图所示，对page结构有一定了解之后再看下面的图效果更好：</p>
<p><img src="/images/mysql/page结构详细.png" alt=""></p>
<h2 id="file-header"><a href="#file-header" class="headerlink" title="file header"></a>file header</h2><p>关于页的结构以及数据在表空间文件中的存储格式，<code>Mysql技术内幕：innodb存储引擎(第2版)</code>书中描述的特别清晰经典，而且很容易读懂和理解，所以本节内容就主要罗列书中所讲内容并加以整理。file header记录了当前页的一些头信息，具体如下图所示：<br><img src="/images/mysql/fileheader.png" alt=""></p>
<h2 id="page-header"><a href="#page-header" class="headerlink" title="page header"></a>page header</h2><p>在表空间文件的二进制数据中，位于page部分最前面的38×8个0和1是file header，而紧跟其后的56×8个0和1就是page header的内容，page header记录的是页的状态信息。具体结构如下图所示：<br><img src="/images/mysql/page header.png" alt=""></p>
<p>关于infimun和supermum两条记录，是在页刚创建的时候就创建的，并且任何时候都不会被删除，infimun记录是比页内任何主键都要小的值，supermum则相反。这两条伪记录在page中如下图所示：<br><img src="/images/mysql/伪记录.png" alt=""></p>
<p>至于user records，里面存放的一条条的用户行记录，关于行记录，下节具体讲，这里先略过。</p>
<h2 id="page-dictionary"><a href="#page-dictionary" class="headerlink" title="page dictionary"></a>page dictionary</h2><p>page dictionary我个人觉得是一个比较难理解透彻的概念，也是我初次学习Innodb时候比较困惑的地方。</p>
<p>前面的page header中有2个字节的PAGE_N_DIR_SLOTS，标识当前page中page dictionary有多少个slot(槽)，每个槽占2个字节，每个槽内存放的是该槽内第一条数据在page内的相对位置。</p>
<p>这句话可能比较难理解，具体什么是槽，槽里面存放的是什么？(既然每个槽只有2个字节，那能存的内容必然很少，必然不会是多条记录的指针，更不会是多条记录数据)。</p>
<p>举个例子可能更好理解。这里选用书中的例子进行分析，依然是创建一个测试表，里面插入一些测试数据，然后用UE等软件查看表空间文件的二进制数据，来看清楚到底page在文件中的一个个部分是如何存储的，包括header、数据记录、以及比较难理解的page dictionary。下面是来自书中的一些截图，这些截图绝大部分看了之后会对page的数据存储理解的很清晰，但对page dictionary反而更疑惑了。<br>下图是数据，本例子是创建了一个表，有两个字段a和b，a是自增主键，b是char(10)。<br><img src="/images/mysql/数据1.png" alt=""></p>
<p>插入这些数据后(100条)，表空间文件中可以预料到会有几个页，其中由于每条数据都很小，而且只有100条，总字节数不到16K，所以数据叶子节点不会分裂，该表空间文件中只会有1个B+Tree Node Page，我们只要找到这个page就可以将这个数据page的二进制存储一条条的剖析清楚。想找到这个数据page并不难，比如可以直接在文件中搜”64 64 64 64 64 64 64 64 64 64”，为什么搜这个呢？因为d的ASCII对应的就是64，搜这个可以迅速定位到数据page的user records部分，那么再往前一定的字节数就是该page的开头。</p>
<p>当前page的开头部分是file header，这里比较简单，而且很容易理解，不过出于完整性考虑，还是把书中的结果截图下来，这样能对整片内柔有个完整的理性认知。<br><img src="/images/mysql/fileheader二进制.png" alt=""></p>
<p>关于file header比较简单，确实没什么可说的，对照下前面的各个字段的含义即可。</p>
<p>紧跟着是后面56字节的page header，这部分就相对来说重要一些，记录了非常多的当前page的重要信息，如下图所示：<br><img src="/images/mysql/page header二进制.png" alt=""></p>
<p>PAGE_N_DIR_SLOTS=0x001a表示当前page有26个槽(100条记录，26个槽，大家先有个感性认知)。</p>
<p>page header后面就是infimun和supermum两条记录，并且这两条记录在文件中是紧挨着存储的，如下图所示：</p>
<p><img src="/images/mysql/伪记录二进制.png" alt=""></p>
<p>可以看到，两条伪记录在文件中的二进制直接就是infimun和supermum这几个字母的ASCII！</p>
<p>后面的内容就是真正的user records，这部分内容我们暂时不关心，我们直接看这里最关心的内容，也就是page dictionary中到底存了什么。如下图所示：<br><img src="/images/mysql/dictionary.png" alt=""></p>
<p>刚才我们已经说过，当前页中有26个槽，每个槽2个字节，而且page dictionary是逆序存放的，所以看图中从00 63到00 70刚好是26个槽，也就是说第1个槽中存的就是00 63，最后一个槽中存的就是00 70。那么这个00 63以及00 70到底是什么？</p>
<p>细心的朋友可能以及发现了，00 63就是当前page的第一行记录的相对位置！就是infimun！上面图中我做了标注，可以看到0xc063地址刚好存的就是infimun的首字母i的ASCII码值。那么显而易见，最后一个槽00 70必然是指向最后一行记录supermum。</p>
<p>此时就很清晰的知道了page dictionary中到底存了什么。但是这并不解决疑问，依然还有很多疑问。</p>
<p>page中每一个记录行，都有一个record header，这个头部里面记录了一些非常重要的信息，比如next record指向下一行地址，比如n_owned表示刚行记录所“包含”(或者称为所管辖)的行记录数。</p>
<p>初学的时候肯定会很疑惑n_owned是做什么的？每一行不就是每一行吗，不应该是相互独立的吗，最多是有next record将这些行串起来，为什么还有n_owned?其实这个属性和page dictionary密切相关。</p>
<p>我们先来看下面一张图:</p>
<p><img src="/images/mysql/slots.png" alt=""></p>
<p>由于page dictionary是逆序存储，所以图中supermum在第一个，infimun在最后一个。其中infimun行的n_owned固定为1，而supermum的n_owned取值范围是[1,8]。至于其余普通记录的n_owned,由于普通slot插入一条数据时，如果被插入的普通slot或者supremum的n_owned已经是8，那么slot需要分裂，所以普通记录的n_owned取值范围是[4,8]。</p>
<p>由上述图可以比较清晰的看出，一个slot中虽然只存了第一条记录的指针(暂且称之为指针，因为文件中存的是相对地址，加载到内存中之后应该就是指向具体的记录)，然由于每条记录直接都是通过链表连接起来的，所以可以从第一条记录依次找到第n_owned条记录。</p>
<p>至此，关于page dictionary就真的懂了吗？没有！起码我看到这里的时候，即使对于表空间文件中每个字节标识什么都清楚了，依然有疑惑，而且这个疑惑书上没讲清楚，网上也没有找到任何痕迹来说。</p>
<p>前面我们说过，由于B+树索引的特性，通过索引(比如主键索引，其实就算不是主键索引，最终也是先找到主键，然后再通过主键索引定位到具体page)可以定位到具体page，比如要找主键id=5的记录，就先找到了当前记录所在的page，这是很简单也很容易理解的，但是当前page中有很多条记录，用户只要一条，是不是还需要将page内的id=5的这条记录找到呢？</p>
<p>前面我们也说了，一旦找到了page之后，在page内再二分查找具体记录所消耗的时间几乎可以忽略不计，也就是说作为一名程序员应该是更关注怎么利用好索引找到page即可，剩下的再根据page dictionary使用二分查找到具体的记录的细节应该是不用完全理解透的，但是，这一点看的确实非常有疑惑，这个疑惑不解决非常难受！</p>
<p>疑惑在什么地方呢？说是使用二分查找，哪什么进行二分查找？刚才我们都已经看到了，page dictionary存的是相对地址，而不是主键！既然是存的地址不是主键，那怎么根据主键二分查找？？</p>
<p>书中的例子为了便于大家理解page dictionary真的是很好，这里也引用下书中的例子，确实对第一次接触page dictionary这个概念的时候帮助了很多。</p>
<p>比如如果有主键为a,b,c,d,e,f,g,h,i,j,k,l的12条数据，假设一共有3个槽，那么显而易见每个槽负责4条记录，所以page dictionary中的内容可能是(a,e,i)。</p>
<p>通过这个例子，就很容易理解槽和n_owned的概念，但是这只是为了便于理解才举的例子，刚才我们已经看到了，page dictionary中存放的是地址，而非主键，既然是地址，那还如何排序？更别谈二分查找了。</p>
<p>所以最初学到这里的时候确实很困惑，但实际上，我忽略了很重要的一点，依然是物理存储和逻辑存储(也就是磁盘和内存)的区别。我们前面通过UE等工具直接查看表空间文件的二进制数据，将innodb的数据存储剖析的一丝不挂，但这毕竟是在磁盘上，当用户根据索引进行查找到page之后，是在磁盘中对page dictionary进行搜索具体记录吗？肯定不是啊，innodb会将page加载到内存中，到了内存中之后(page就变成了C语言中的一个结构体对象)，作为程序员理应知道，page dictionary里面存的地址那就是指向具体记录的指针！</p>
<p>既然有了指针，那么就能获取到主键，而主键又是排序后的，为何不能二分查找呢？所以说，这个例子说page dictionary中存的是主键也是可以理解的！</p>
<h2 id="行记录"><a href="#行记录" class="headerlink" title="行记录"></a>行记录</h2>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/19/mysql/innodb机制详解一：概述及内存模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/19/mysql/innodb机制详解一：概述及内存模型/" itemprop="url">innodb机制详解一：概述、体系架构和内存模型</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-19T00:00:00+08:00">
                2017-10-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mysql/" itemprop="url" rel="index">
                    <span itemprop="name">mysql</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>关系型数据库在各种企业应用中的重要性和地位都不言而喻，Mysql作为开源关系型数据库中最受欢迎的数据库，不管从任何角度来说，掌握好他都是必须的。而innodb存储引擎，作为mysql5.5版本之后的默认存储引擎，可以说是mysql中最优秀的存储引擎。</p>
<p>关于innodb的一些特性和优点，比如行级锁、事务多段回滚、插入缓冲、double write等等的网上随处可见，作为一名开发人员，即使不是专门的DBA，我认为也必须了解innodb内部运作机制。因为我们常说的一些sql优化等各种优化策略，如果没有一定的理论依据，那只能是听到别人说什么就是什么，没有自己的判断依据，当数据库运行出了问题也无从分析。</p>
<p>为此，也为了巩固自己所学的知识，所以开了Innodb这个博客分类，将自己对Innodb的认知写出来，该系列博客内容主要参考了<code>Mysql技术内幕：innodb存储引擎(第2版)</code>以及<code>Mysql内核:innodb存储引擎</code>两本书。这两本书每本都看了2遍左右，相互应征着学习。在第一次看这2本书的时候，有特别多的困惑和不解的地方，前者主要是从应用角度介绍innodb，后者主要是从源码角度讲解innodb。初次读这2本书的时候，遇到的困惑很多，我也大量查阅了网上的很多资料，也没找到能把这些困惑说清楚的(其实是压根没找到类似的内容和文章，内容都是千篇一律，不知道这些博客作者是没考虑到这些问题还是说这些问题只有小白菜鸟才不懂)。我个人非常尊重这2本书的作者，这两本书是我看过讲Innodb最好最透彻的书，但可能是因为我自己理解能力不够，觉得书中某些地方并没有完全讲清楚，对于一些初步了解innodb的读者来说，肯定会产生不少困惑。因为写书的人水平极高，所以一些站在写书人角度上来说完全不是问题的问题，可能反而成了困扰初学者的地方。</p>
<p>基于这些原因，我会把学习innodb过程中自己的认知以及困惑和解决这些困惑的心得全部用自己最白话的语言写出来，希望能帮助到自己以及其他初学者。</p>
<p>关于Innodb的工作原理，我个人认为作为一名程序员，主要需要理解以下几个模块：innodb体现架构和内存模型、日志文件及表空间、B+树索引、innodb的锁、事务。如果能深刻理解这些模块的原理，我觉得在日常开发中编写和mysql相关的程序时，心里会更加自信和有底气。</p>
<h1 id="innodb体系架构"><a href="#innodb体系架构" class="headerlink" title="innodb体系架构"></a>innodb体系架构</h1><p>关于innodb的体系架构和内存模型，下面这张图展示的非常清晰完整。</p>
<p><img src="/images/mysql/innodb体系架构和内存模型.png" alt=""> </p>
<p>我个人认为，想要理解好innodb的工作原理，必须非常清晰的认识理解innodb的内存模型！在学习innodb的过程中，对我产生的一个非常大的困惑之一就是关于磁盘和内存。在innodb中，有很多概念(比如page、insert buffer、索引等)，都是即存在磁盘中，也可能存在内存中(一般来说是缓冲池中)，而在书中的讲述中，并没有非常细致的讲清楚这些基本问题(可能是因为这些概念太基础了，作者默认读者都懂)，但我觉得应该很多初学者都会困惑。</p>
<p>比如说到insert buffer，到底是指缓冲池中的insert buffer还是磁盘中的insert buffer?我们知道，insert buffer内部也是采用的B+树数据结构，那么在内存中是B+树的数据结构很容易理解，在磁盘中也是存储成B+树结构吗？是怎么存的呢？直接内存镜像dump还是二进制序列化？说到B+树二级索引的合并，到底是怎么合并？依据什么合并？是合并到缓冲池还是直接写入磁盘？</p>
<p>上述这些问题，只是我在学习Innodb过程中的困惑之一，这些内容书中确实没有讲的非常细，只能个人自己摸索，我相信应该会有不少初学者也有类似的困惑。</p>
<p>其实产生这些困惑的原因就在于没有理解好innodb的体系结构，没有理解好innodb的内存模型。想要讲清楚这些概念，不是几句话的事，而且牵扯到的概念也比较多，我的目的就是通过这一系列的文章，将自己对innodb的认知写出来，由于本人水平有限，所以难免有错误的地方，希望有不同意见的朋友能一起讨论，共同进步。</p>
<p>从上图中我们可以看到，Innodb的体系结构可以认为分层3个部分。</p>
<ol>
<li><p>内存模型。内存模型中包括了缓冲池(innodb buffer pool)、其他内存(Additional buffer pool)和日志缓存(log buffer，其实主要是redo log)。</p>
</li>
<li><p>各种线程。innodb的大部分工作都是基于多线程模型实现的，内部有很多种线程，比如Main Thread、IO Thread、Purge Thread、Clean Thread等等。对于不同版本的innodb，具体的线程及线程的负责工作的内容都可能不太一样，但整体差别不是很大，并不影响我们理解innodb的工作模式。</p>
</li>
<li><p>innodb的磁盘存储系统。innodb毕竟是一个mysql存储引擎，作为关系型数据库，数据的完整性是第一位的，所以必然少不了数据的持久化。这部分就决定了innodb的数据以及索引是在磁盘中怎样存储的，同时为了数据容灾等考量，各种日志文件也需要持久化到磁盘，所以innodb的磁盘存储我们主要需要理解：系统表空间存储、用户表空间存储、各种日志文件的存储。</p>
</li>
</ol>
<h1 id="innodb的缓冲池"><a href="#innodb的缓冲池" class="headerlink" title="innodb的缓冲池"></a>innodb的缓冲池</h1><p>我个人认为Innodb Buffer Pool(缓冲池)是innodb内存模型中最重要的概念。简单来说，我们可以理解为缓冲池就是一块普通的内存区域，这块内存区域是归属于innodb来管理的。</p>
<p>由于CPU处理数据的速度和从磁盘读取速度的天差地别，所以为了高速读写数据，innodb必须将磁盘中存储的数据(包括索引和数据以及一些日志文件)读取到内存中来，这块内存就叫做innodb的缓冲池。innodb每次从磁盘中读写数据的最小单位可不是byte哦，也不是扇区这种，而是称为page。一个page默认大小是16KB，一般来说，每次从磁盘中读取数据都是一次性读取或写入多个page。page的具体细节后面的文章在详细讲述，这里我们只需要有一个感性认识即可。</p>
<p>因此，我们可以感性的将缓冲池理解为很多个page的组合。当然，同样是page，也有多种类型的page。比如有的page存的是数据，有的page存的是二级索引，有的page存的是Undo信息(具体什么是undo page后面文章详解)。</p>
<p>既然知道了缓冲池的大概组成，我们来想一个问题，当用户向innodb引擎的表中插入一条数据时，由于最终数据会落到磁盘文件中，那么是直接调用类似与writeFile等等的函数向某个磁盘文件中在某个合适的位置(或者是末尾追加)写入一条数据吗？答案肯定是否定的。我们知道磁盘IO相比于内存读写，速度完全不是一个量级的，对于大型互联网企业应用的mysql数据库，数据库的频繁读写是少不了的，如果每条语句都直接写入磁盘，那即使做了再多的读写分离，每个数据库实例所能承载的并发连接也扛不住，用户体验自然也极差。</p>
<p>所以说，当用户插入一条数据时，是先写入缓冲池中的某几个页(因为可能不止写数据，还可能写了二级索引，而且还会向undo页等页中写入一些信息)，然后等到合适的时机，再由内部的工作线程将这些修改后的页(称为脏页)刷新到磁盘。不过并不是每次有脏页就立即被刷新到磁盘，而是基于一个checkpoint机制在合适的时机刷新到磁盘。</p>
<p>可以为innodb设置多个缓冲池实例，以减少数据库内部资源竞争，提高并发能力。(默认为1个实例，具体设置多少合适应该要根据实际情况具体来定)</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like '%innodb_buffer_pool_instances%';</span><br><span class="line">+<span class="comment">------------------------------+-------+</span></span><br><span class="line">| Variable_name                | Value |</span><br><span class="line">+<span class="comment">------------------------------+-------+</span></span><br><span class="line">| innodb_buffer_pool_instances | 1     |</span><br><span class="line">+<span class="comment">------------------------------+-------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<h2 id="LRU-List、Free-List、Flush-List"><a href="#LRU-List、Free-List、Flush-List" class="headerlink" title="LRU List、Free List、Flush List"></a>LRU List、Free List、Flush List</h2><p>经过前面的讲述我们知道缓冲池里面存放了多种类型的page，那么这些page是如何被管理的呢？其实就是基于LRU List、Free List、Flush List这三个链表进行管理的。</p>
<p>这三个链表具体是什么东东？和缓冲池又有什么关系？前面我们对缓冲池有了一个比较感性的认知，下面从伪代码角度来理性认识下缓冲池。缓冲池是一块内存区域，每一个缓冲池实例其实是有一个struct结构体对象与之对应的，这个struct结构体对象有以下一些属性(只列举了部分)</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// buf_pool_struct结构体</span></span><br><span class="line"></span><br><span class="line">frame_mem   <span class="comment">//缓冲池内存起始地址</span></span><br><span class="line">high_end    <span class="comment">//缓冲池内存终止地址</span></span><br><span class="line">blocks      <span class="comment">//这是一个数组对象，里面存放的是一个个的page!  每一个page也对应一个结构体对象buf_block_struct</span></span><br><span class="line">flush_list  <span class="comment">//指向了Flush List这个链表的首地址，也就是指向的是一个buf_block_struct，下面两个链表同理！</span></span><br><span class="line"><span class="built_in">free</span>        <span class="comment">//指向了Free List这个链表的首地址！</span></span><br><span class="line">LRU         <span class="comment">//指向了LRU List这个链表的首地址！</span></span><br><span class="line">LRU_old     <span class="comment">//指向了LRU List这个链表的old端的首地址，也是指向一个buf_block_struct对象</span></span><br><span class="line">LRU_old_len <span class="comment">//old端的page数量</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>通过上面这个结构体，我们对缓冲池这个对象结构有了比较理性的认识，也知道了LRU List、Free List、Flush List这三个链表其实就是缓冲池对象的3个属性，缓冲池中几乎所有的page都在这三个链表中(有些page不在，等讲到的时候再说，这里可以暂时理解为几乎所有的页都被这三个链表贯穿起来组成了缓冲池)。</p>
<p>Free List表示所有缓冲池中空闲的页，LRU List表示所有缓冲池中已使用的页，Flush List表示所有缓冲池中的脏页(也即等待被刷新到磁盘上的页)。需要注意的是，脏页即在Flush List，也在LRU List中(也即两个链表中同时记录了脏页buf_block_struct对象的指针)。三者的关系如下图所示：<br><img src="/images/mysql/list.png" alt=""> </p>
<p>我们可以使用mysql提供的命令查看这三个链表的一些信息:<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show engine innodb status\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">  Type: InnoDB</span><br><span class="line">  Name: </span><br><span class="line">Status: </span><br><span class="line"><span class="comment">-- 中间省略了很多信息</span></span><br><span class="line"><span class="keyword">INSERT</span> BUFFER <span class="keyword">AND</span> ADAPTIVE <span class="keyword">HASH</span> <span class="keyword">INDEX</span></span><br><span class="line"><span class="comment">-------------------------------------</span></span><br><span class="line">Ibuf: <span class="keyword">size</span> <span class="number">1</span>, free <span class="keyword">list</span> <span class="keyword">len</span> <span class="number">3</span>, seg <span class="keyword">size</span> <span class="number">5</span>, <span class="number">0</span> merges</span><br><span class="line">merged <span class="keyword">operations</span>:</span><br><span class="line">...</span><br><span class="line"><span class="keyword">Hash</span> <span class="keyword">table</span> <span class="keyword">size</span> <span class="number">276671</span>, node <span class="keyword">heap</span> has <span class="number">7</span> buffer(s)</span><br><span class="line"><span class="comment">--------------------------------------------------</span></span><br><span class="line">BUFFER POOL <span class="keyword">AND</span> <span class="keyword">MEMORY</span></span><br><span class="line"><span class="comment">----------------------</span></span><br><span class="line">Total <span class="keyword">memory</span> allocated <span class="number">137363456</span>; in additional pool allocated 0</span><br><span class="line">Dictionary memory allocated 4421041</span><br><span class="line">Buffer pool size   8191</span><br><span class="line">Free buffers       3749</span><br><span class="line">Database pages     4435</span><br><span class="line">Old database pages 1657</span><br><span class="line">Modified db pages  0</span><br><span class="line">Pending reads 0</span><br><span class="line">Pending writes: LRU 0, <span class="keyword">flush</span> <span class="keyword">list</span> <span class="number">0</span>, single page <span class="number">0</span></span><br><span class="line">Pages made young <span class="number">0</span>, <span class="keyword">not</span> young <span class="number">0</span></span><br><span class="line"><span class="number">0.00</span> youngs/s, <span class="number">0.00</span> non-youngs/s</span><br><span class="line">Pages <span class="keyword">read</span> <span class="number">4435</span>, created <span class="number">0</span>, written <span class="number">2</span></span><br><span class="line"><span class="number">0.00</span> <span class="keyword">reads</span>/s, <span class="number">0.00</span> creates/s, <span class="number">0.00</span> writes/s</span><br><span class="line"><span class="keyword">No</span> buffer pool page gets since the <span class="keyword">last</span> printout</span><br><span class="line">Pages <span class="keyword">read</span> ahead <span class="number">0.00</span>/s, evicted <span class="keyword">without</span> <span class="keyword">access</span> <span class="number">0.00</span>/s, Random <span class="keyword">read</span> ahead <span class="number">0.00</span>/s</span><br><span class="line">LRU <span class="keyword">len</span>: <span class="number">4435</span>, unzip_LRU <span class="keyword">len</span>: <span class="number">0</span></span><br><span class="line">I/O <span class="keyword">sum</span>[<span class="number">0</span>]:cur[<span class="number">0</span>], unzip <span class="keyword">sum</span>[<span class="number">0</span>]:cur[<span class="number">0</span>]</span><br><span class="line"><span class="comment">--------------</span></span><br><span class="line">============================</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="keyword">row</span> <span class="keyword">in</span> <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure></p>
<p>可以看到缓冲池一共有Buffer pool size   8191个page，其中有Free buffers       3749,LRU len: 4435。我们来做一个算数运算，Free+LRU=8184。并不等于缓冲池大小8191.还差了7个page。</p>
<p>我们刚才说到，并不是所有的page都在free list和lru list中，比如hash索引页和insert buffer页就不归这三个链表管理(但这两种页依然是从free list申请，不过申请后不归lru管理)，我们发现<code>Hash table size 276671, node heap has 7 buffer(s)</code>，也就是剩下的7个page刚好是hash索引页。</p>
<p>熟悉链表数据结构的朋友应该都知道，链表中每个节点直接内存地址并不一定是连续的，由此对于缓冲池的内存模型更具体的分布图大致如下图所示：<br><img src="/images/mysql/buffer pool.png" alt=""> </p>
<p>图中每一个方块对应一个page，这么多page通过free list和lru list两个链表贯穿起来，再加上insert buffer和lock info page和hash index page，这么多page就组成了一个缓冲池实例。</p>
<p>到现在为止，我们对缓冲池应该理解的比较透彻清晰了，但是本节的主题LRU List到底是个什么东东还没讲到，下面就重点讲这三个链表。</p>
<p>当用户执行sql查询数据库时，如果缓冲池中已经有该页的信息，那么就直接从该页读取；如果缓冲池中没有，那么就需要从磁盘读取对应位置的page(根据表空间id以及表空间内的偏移量offet定位到具体磁盘文件中的位置)并加载到缓冲池。但是，缓冲池那么大，新加在的page放到哪呢？</p>
<p>innodb内部大致工作流程如下，当发现缓冲池中没有用户所需的page时，调用内部某函数从磁盘对应位置加载相应的page到缓冲池中，此时就需要从free list中申请对应数量的page，如果free list有足够的page，就将新申请到的page添加到LRU List中。</p>
<p>但是需要注意，LRU List这个链表分为两个部分，old区域和new区域，一般来说，new区域存放的都是热点页(也就是被频繁访问的page)，old区存放的是访问不频繁的页。LRU List从起始位置一直到某个临界点，都是new区域，后面的都是old区域。这个临界点也叫midpoint位置，如下图所示：<br><img src="/images/mysql/midpoint.png" alt=""> </p>
<p>回过头看缓冲池结构体对象，发现有两个属性<code>LRU_old</code>和<code>LRU_old_len</code>，这两个属性就将LRU List划分成了2个区域。</p>
<p>新读取的page，并不是直接放在LRU链表的首部，而是放在Midpoint位置。这个位置默认为整个LRU链表的5/8，也就是说默认情况下young区域占5/8，old区域占3/8。这个参数是用户可以调整的，如下所示：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like '%innodb_old_blocks_pct%';</span><br><span class="line">+<span class="comment">-----------------------+-------+</span></span><br><span class="line">| Variable_name         | Value |</span><br><span class="line">+<span class="comment">-----------------------+-------+</span></span><br><span class="line">| innodb_old_blocks_pct | 37    |</span><br><span class="line">+<span class="comment">-----------------------+-------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure></p>
<p>可以看到默认情况下，old_blocks所占百分比为37%，也即3/8。如果觉得我们的热区数据不止63%的话，可以将old的比例调低以提升性能。</p>
<p>也就是说，新插入的page是放在LRU链表的LRU_old属性后面的，大概位置在距离LRU首部节点5/8位置。那么这样做的目的是什么呢？为什么不直接将新读取到的page放在LRU链表首部？</p>
<p>举个例子，很多时候用户执行一条查询，所查询到的结果很可能是多个page，此时free链表很可能已经被用光了，那么就必须删除一些LRU末尾的页来给新页腾出位置，如果用户此次查询需要的page非常多，如果直接放到LRU首部，就很可能将真正的热区数据page从LRU删掉，而新加入的page有可能只是此次查询才会用到。这样的话，正在的热区数据被冷数据淘汰，显然会影响性能，所以才将新加入的页插入到midpoint位置。</p>
<p>当新加入的页再次被访问时，就会调用buf_LRU_make_block_young函数将其移动到链表的头部。不过需要注意的是，在LRU尾部被淘汰的页必须满足以下条件：页不是脏的、页没有正在被其他线程使用。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Database pages     4435     <span class="comment">--LRU链表总长度</span></span><br><span class="line">Old database pages 1657     <span class="comment">--Old区域长度</span></span><br><span class="line">Pages made young 0          <span class="comment">--该项表示page被移动到LRU首部的次数</span></span><br></pre></td></tr></table></figure></p>
<p>从上述信息来看，old长度/总LRU长度(1657/443=0.37)刚好等于37%。</p>
<p>我们已经对缓冲池的认识比较深刻了，那么缓冲池的大小怎么查看或设置呢？<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like '%innodb_buffer_pool_size%';</span><br><span class="line">+<span class="comment">-------------------------+-----------+</span></span><br><span class="line">| Variable_name           | Value     |</span><br><span class="line">+<span class="comment">-------------------------+-----------+</span></span><br><span class="line">| innodb_buffer_pool_size | 134217728 |</span><br><span class="line">+<span class="comment">-------------------------+-----------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure></p>
<h2 id="checkpoint机制"><a href="#checkpoint机制" class="headerlink" title="checkpoint机制"></a>checkpoint机制</h2><p>我们先来讲清楚为什么有checkpoint机制以及这个机制是做什么的。</p>
<p>此前我们讲到，当用户插入数据时，必然是将数据先插入缓冲池，然后在找一个合适的时机同步到磁盘中进行持久化。那么这个时机就很关键，如果过于频繁的同步，显然会影响性能。</p>
<p>另外还有一个问题，如果在还未同步到磁盘或者正在同步的过程中数据库宕机，那么就会产生数据丢失，所以innodb采用了write ahead log的方式。也就是当事务提交时，先写redo log，再修改page。而写redo log可以认为是原子性操作(因为是基于扇区写入)，所以即使写入过程数据库宕机，只要redo log写入成功，当数据库再次启动时就可以重放redo log进行数据恢复。</p>
<p>既然有了redo log是不是可以不将数据从缓冲池中同步到磁盘呢？所有page都在缓冲池中性能岂不是非常高？问题在于，随着数据量增大，缓冲池几乎不可能将所有数据全部缓存，另外如果一直不同步，那么redo log就会无线增大，所以显然是不可取的。另外就是，即使内存够大，redo log文件大小无限制，但如果数据库宕机再次启动时，从redo log进行数据恢复岂不是要非常久？这对于生产环境下就和灾难一样。</p>
<p>正是因为上述的一些原因，才有了checkpoint机制。由此可见checkpoint机制主要解决以下问题：</p>
<ol>
<li>缩短数据库恢复时间</li>
<li>缓冲池不够用时，将脏页刷到磁盘</li>
<li>redo log不可用时，将脏页刷到磁盘</li>
</ol>
<p>关于第一点，数据库宕机恢复时，并不需要重放所有的日志，只需要重放checkpoint后的日志，这样自然极大缩短了恢复时间。</p>
<p>关于第二点，如果缓冲池不够用(也即是free list耗尽)，需要删除LRU尾端最少使用的页，如果此页为脏页，则会强制进行checkpoint将脏页刷到磁盘。</p>
<p>关于第三点，redo log文件并不是只有1个，而且并不是无线增大，而是当redo log大到一定程度的时候，新的log内容要覆盖老内容，那么再次之前就必须强制进行checkpoint，将缓冲池中脏页至少刷新到当前redo log的位置。</p>
<p>对于innodb来言，内部有LSN进行标识，每个page有LSN，redo log也有LSN，checkpoint也有LSN，可以通过下面命令查看他们的LSN。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show engine innodb status\G;</span><br><span class="line"><span class="comment">-- 其他无关信息省略...</span></span><br><span class="line">LOG</span><br><span class="line"><span class="comment">---</span></span><br><span class="line">Log sequence number 2576750188</span><br><span class="line">Log flushed up to   2576750188</span><br><span class="line">Last checkpoint at  2576750188</span><br><span class="line">0 pending log writes, 0 pending chkp writes</span><br><span class="line">14 log i/o's done, 0.00 log i/o's/second</span><br><span class="line"><span class="comment">----------------------</span></span><br></pre></td></tr></table></figure></p>
<p>innodb有两种checkpoint，sharp checkpoint和fuzzy checkpoint。</p>
<p>当数据库关闭时会执行sharp checkpoint将所有脏页刷新到磁盘，而在innodb运行过程中是进行fuzzy checkpoint每次只刷新部分脏页到磁盘。下面讲述有哪些情况会导致fuzzy checkpoint。</p>
<ol>
<li>Main Thread会每秒及每10秒异步的从flush list中刷新一部分脏页到磁盘</li>
<li><p>LRU list需要保证有一定量的page可用，从mysql5.6版本以后，若lru列表中没有足够的可用页，则会移除最少使用页，如果要移除的是脏页，则需要进行fuzzy checkpoint。可用页的数量默认为1024，可以通过如下命令查看：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like '%innodb_lru_scan_depth%';</span><br><span class="line">+<span class="comment">-----------------------+-------+</span></span><br><span class="line">| Variable_name         | Value |</span><br><span class="line">+<span class="comment">-----------------------+-------+</span></span><br><span class="line">| innodb_lru_scan_depth | 1024  |</span><br><span class="line">+<span class="comment">-----------------------+-------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
<p> 检查lru是否有足够的page以及移除这些页是page clean thread进行的，不会阻塞用户主线程查询操作。</p>
</li>
<li>当redo log不可用时也会发生fuzzy checkpoint。为了简单理解，我们可以认为不可用是指redo log的lsn已经比checkpoint的lsn大了很多了，导致redo log文件过大，需要进行fuzzy checkpoint来使checkpoint的lsn追上redo log，从而可以使原有的redo log内容被覆盖。具体细节大家可以参考<code>Mysql技术内幕：innodb存储引擎(第2版)</code>这本书。</li>
<li>最后一种fuzzy checkpoint是因为缓冲池中脏页太多导致强制进行fuzzy checkpoint刷新脏页到磁盘，那么怎么才算脏页过多呢？innodb提供了对应参数供用户设置，默认为75%<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like '%innodb_max_dirty_pages_pct';</span><br><span class="line">+<span class="comment">----------------------------+-----------+</span></span><br><span class="line">| Variable_name              | Value     |</span><br><span class="line">+<span class="comment">----------------------------+-----------+</span></span><br><span class="line">| innodb_max_dirty_pages_pct | 75.000000 |</span><br><span class="line">+<span class="comment">----------------------------+-----------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="innodb的Main-Thread"><a href="#innodb的Main-Thread" class="headerlink" title="innodb的Main Thread"></a>innodb的Main Thread</h1><p>innodb内部工作线程有很多，我个人觉得如果不是专业做DBA或者数据库内核开发的，普通数据库应用人员应该不需要知根知底的了解透彻每一个线程具体是做什么的以及具体有哪些线程，更何况不同的innodb版本里面线程种类、数量及负责的工作职责可能都不太一样，我们只需要理解个大概就足够了。</p>
<p>对于innodb来说，最重要的就是主线程。<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show engine innodb status\G;</span><br><span class="line"><span class="comment">-- 中间省略了很多无关信息</span></span><br><span class="line">BACKGROUND THREAD</span><br><span class="line"><span class="comment">-----------------</span></span><br><span class="line">srv_master_thread loops: 323 1_second, 323 sleeps, 29 10_second, 33 background, 33 <span class="keyword">flush</span></span><br><span class="line">srv_master_thread <span class="keyword">log</span> <span class="keyword">flush</span> <span class="keyword">and</span> writes: <span class="number">323</span></span><br><span class="line"><span class="comment">----------</span></span><br></pre></td></tr></table></figure></p>
<p>可以看到，innodb在这段时间内，执行了323此每隔1秒的操作，每隔10秒的操作执行了29次，background和flush各执行了33次。</p>
<p>那么什么是每隔1秒的操作以及每隔10秒的操作呢？其实这就是master thread的工作内容，分别是每1秒一次的循环，以及每10秒一次的循环。</p>
<p>这里就以每10秒一次的操作为例来说明把，以便对于后面博客其他内容有个感性认知，以及对本篇博客的一个更加全面的补充。</p>
<p>master线程每隔10秒会做如下事情：</p>
<ol>
<li><p>刷新一定数量(因版本而不同，大概是100-200多个，而且用户可调整)的脏页到磁盘。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like '%innodb_io_capacity%';</span><br><span class="line">+<span class="comment">--------------------+-------+</span></span><br><span class="line">| Variable_name      | Value |</span><br><span class="line">+<span class="comment">--------------------+-------+</span></span><br><span class="line">| innodb_io_capacity | 200   |</span><br><span class="line">+<span class="comment">--------------------+-------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.01</span> sec)</span><br></pre></td></tr></table></figure>
</li>
<li><p>合并一定数量的插入缓冲(具体什么是插入缓冲以及如何合并，在后面博客中详细讲解)，这个数量一般是innodb_io_capacity的5%</p>
</li>
<li>将日志缓冲刷新到磁盘</li>
<li>删除一定数量的无用undo page，这个数量默认是20个，而且可以调整，如下所示：<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like '%innodb_purge_batch_size%';</span><br><span class="line">+<span class="comment">-------------------------+-------+</span></span><br><span class="line">| Variable_name           | Value |</span><br><span class="line">+<span class="comment">-------------------------+-------+</span></span><br><span class="line">| innodb_purge_batch_size | 20    |</span><br><span class="line">+<span class="comment">-------------------------+-------+</span></span><br><span class="line">1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>这是innodb系列博客的第一篇，主要讲了innodb的体系结构及内存模型，这一篇博客中的内容对于后续的博客至关重要，必须要深刻理解缓冲池、LRU、page等概念才能更好的理解后续内容。</p>
<p>后面的博客文章中，将会陆续展开各个模块的内容，比如关于日志文件(undo log、redo log、binlog)、表结构和表空间及page、索引、插入缓冲及Innodb其他特性、锁与事务。</p>
<p>这些模块各个都是innodb的核心，理解这些概念对日常mysql开发至关重要。当然对于mysql来说还有很多其他重要的内容，比如分区、分表分库、主从复制、读写分离、热备份及数据迁移以及sql调优和性能监控，这些内容相对来说更偏向运维一些(sql调优和性能优化对于运维和开发人员来说同样重要)，总之…程序员的路远得很，这还只是一个mysql数据库模块…哎慢慢搞把~</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/18/java/基于NIO实现客户端与服务端聊天程序/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/18/java/基于NIO实现客户端与服务端聊天程序/" itemprop="url">基于NIO实现客户端与服务端聊天程序</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-18T00:00:00+08:00">
                2017-10-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index">
                    <span itemprop="name">java</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="服务端实现"><a href="#服务端实现" class="headerlink" title="服务端实现"></a>服务端实现</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NioSocketServer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Selector selector;</span><br><span class="line">    <span class="keyword">private</span> ServerSocketChannel server;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> port = <span class="number">8080</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> TIME_OUT = <span class="number">3000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NioSocketServer</span><span class="params">(<span class="keyword">int</span> port)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.port = port;</span><br><span class="line">        server = ServerSocketChannel.open();</span><br><span class="line">        server.socket().bind(<span class="keyword">new</span> InetSocketAddress(port));</span><br><span class="line">        server.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        selector = Selector.open();</span><br><span class="line">        server.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ServerStart</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 如果没有可用事件，selector.select(TIME_OUT)会阻塞TIME_OUT毫秒然后返回0，如果有可用事件则直接返回事件数量</span></span><br><span class="line">            <span class="keyword">int</span> evCount = selector.select(TIME_OUT);</span><br><span class="line">            <span class="keyword">if</span> (evCount == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="comment">// 所有channel向selector注册的事件都会在这里处理</span></span><br><span class="line">            Set&lt;SelectionKey&gt; keys = selector.selectedKeys();</span><br><span class="line">            Iterator&lt;SelectionKey&gt; it = keys.iterator();</span><br><span class="line">            <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">                SelectionKey key = it.next();</span><br><span class="line">                it.remove();</span><br><span class="line">                <span class="keyword">if</span> (key.isAcceptable()) &#123;</span><br><span class="line">                    handleAccept(key);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.isReadable()) &#123;</span><br><span class="line">                    handleRead(key);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.isWritable()) &#123;</span><br><span class="line">                    handleWrite(key);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleAccept</span><span class="params">(SelectionKey key)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 由于是isAcceptable类型的事件，所以key.channel得到的是ServerSocketChannel类型的channel，其实就是server</span></span><br><span class="line">        ServerSocketChannel ssc = (ServerSocketChannel) key.channel();</span><br><span class="line">        SocketChannel client = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            client = ssc.accept();</span><br><span class="line">            client.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">            System.out.println(client.socket().getRemoteSocketAddress() + <span class="string">"已连接..."</span>);</span><br><span class="line">            <span class="comment">// 当有客户端建立好连接后，向客户端发送欢迎信息</span></span><br><span class="line">            String welcome = client.socket().getRemoteSocketAddress() + <span class="string">"，你好，欢迎你！\n"</span>;</span><br><span class="line">            buf.put(welcome.getBytes(<span class="string">"UTF-8"</span>));</span><br><span class="line">            buf.flip();</span><br><span class="line">            <span class="keyword">while</span> (buf.hasRemaining()) &#123;</span><br><span class="line">                client.write(buf);</span><br><span class="line">            &#125;</span><br><span class="line">            buf.clear();</span><br><span class="line">            <span class="comment">//发送完信息后，将这个channel向selector注册一个读事件</span></span><br><span class="line">            <span class="comment">//当这个channel对应的客户端发来数据并且数据可读时，就会selector就会收到通知并放入selector.selectedKeys()中</span></span><br><span class="line">            client.register(selector, SelectionKey.OP_READ, buf);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (client != <span class="keyword">null</span>) client.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                e1.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleRead</span><span class="params">(SelectionKey key)</span> </span>&#123;</span><br><span class="line">        SocketChannel clientChannel = (SocketChannel) key.channel();</span><br><span class="line">        ByteBuffer buf = (ByteBuffer) key.attachment();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//　服务端打印收到的客户端发送来的数据</span></span><br><span class="line">            <span class="keyword">int</span> len = clientChannel.read(buf);</span><br><span class="line">            <span class="keyword">if</span> (len == -<span class="number">1</span> || len == <span class="number">0</span>) &#123;</span><br><span class="line">                clientChannel.close();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                String recMsg = <span class="keyword">new</span> String(buf.array(), <span class="number">0</span>, len);</span><br><span class="line">                System.out.println(clientChannel.socket().getRemoteSocketAddress() + <span class="string">"的数据:"</span> + recMsg);</span><br><span class="line">                buf.clear();</span><br><span class="line">                <span class="comment">// 打印完客户端发送来的信息之后，服务端想要给客户端回应</span></span><br><span class="line">                <span class="comment">//所以向buf中写入了一些信息，并注册OP_WRITE事件，但是注意此时并没有真正向客户端写(虽然此时可以写)</span></span><br><span class="line">                <span class="comment">//而是等待系统告知selector当前这个clientChannel以及可写后才真正去写</span></span><br><span class="line">                <span class="comment">//另外，当服务端向客户端写完之后，一定要取消注册OP_WRITE事件，因为每个channel一直都是可写状态</span></span><br><span class="line">                <span class="comment">//也就是说key.isWritable()返回的一直都是true，所以如果不取消OP_WRITE事件的话服务端就会一直向客户端发送数据</span></span><br><span class="line">                buf.put((<span class="string">"服务端已收到您发送的数据:"</span> + recMsg).getBytes(<span class="string">"UTF-8"</span>));</span><br><span class="line">                clientChannel.register(key.selector(), SelectionKey.OP_WRITE, buf);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (clientChannel != <span class="keyword">null</span>) clientChannel.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                e1.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleWrite</span><span class="params">(SelectionKey key)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//当channel可写时，用客户端发送数据</span></span><br><span class="line">        SocketChannel sc = (SocketChannel) key.channel();</span><br><span class="line">        ByteBuffer buf = (ByteBuffer) key.attachment();</span><br><span class="line">        buf.flip();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (buf.hasRemaining()) &#123;</span><br><span class="line">                sc.write(buf);</span><br><span class="line">            &#125;</span><br><span class="line">            buf.clear();</span><br><span class="line">            <span class="comment">// 写完数据之后，将OP_WRITE事件取消，并且注册OP_READ事件</span></span><br><span class="line">            sc.register(key.selector(), SelectionKey.OP_READ, buf);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (sc != <span class="keyword">null</span>) sc.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                e1.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> NioSocketServer(<span class="number">8555</span>).ServerStart();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="客户端实现"><a href="#客户端实现" class="headerlink" title="客户端实现"></a>客户端实现</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NioSocketClient</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> SocketChannel client;</span><br><span class="line">    <span class="keyword">private</span> Selector selector;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NioSocketClient</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            client = SocketChannel.open();</span><br><span class="line">            client.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            <span class="comment">//在非阻塞模式下，此时调用connect()，该方法可能在连接建立之前就返回了。为了确定连接是否建立，可以调用finishConnect()的方法</span></span><br><span class="line">            client.connect(<span class="keyword">new</span> InetSocketAddress(<span class="string">"127.0.0.1"</span>, <span class="number">8555</span>));</span><br><span class="line">            selector = Selector.open();</span><br><span class="line">            client.register(selector, SelectionKey.OP_CONNECT);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                selector.close();</span><br><span class="line">                client.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                e1.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (client.isConnectionPending()) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span>(client.finishConnect())&#123;</span><br><span class="line">                    client.register(selector, SelectionKey.OP_READ, ByteBuffer.allocate(<span class="number">1024</span>));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    selector.close();</span><br><span class="line">                    client.close();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                    e1.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="keyword">while</span> (scanner.hasNextLine()) &#123;</span><br><span class="line">            String msg = scanner.nextLine();</span><br><span class="line">            <span class="keyword">if</span> (<span class="string">""</span>.equals(msg)) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"exit"</span>.equals(msg)) System.exit(<span class="number">0</span>);</span><br><span class="line">            <span class="keyword">else</span> handle(msg);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(String msg)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> wait = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">while</span> (wait) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">int</span> count = selector.select(<span class="number">3000</span>);</span><br><span class="line">                <span class="keyword">if</span> (count == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">                Set&lt;SelectionKey&gt; keys = selector.selectedKeys();</span><br><span class="line">                Iterator&lt;SelectionKey&gt; it = keys.iterator();</span><br><span class="line">                <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">                    SelectionKey key = it.next();</span><br><span class="line">                    it.remove();</span><br><span class="line">                    <span class="keyword">if</span> (key.isReadable()) &#123;</span><br><span class="line">                        ByteBuffer buf = (ByteBuffer) key.attachment();</span><br><span class="line">                        SocketChannel channel = (SocketChannel) key.channel();</span><br><span class="line">                        buf.clear();</span><br><span class="line">                        channel.read(buf);</span><br><span class="line">                        buf.flip();</span><br><span class="line">                        <span class="keyword">byte</span>[] by = <span class="keyword">new</span> <span class="keyword">byte</span>[buf.remaining()];</span><br><span class="line">                        buf.get(by);</span><br><span class="line">                        System.out.println(<span class="string">"接收到服务端数据:"</span> + channel.socket().getRemoteSocketAddress() + <span class="keyword">new</span> String(by, <span class="string">"UTF-8"</span>));</span><br><span class="line">                        channel.register(selector, SelectionKey.OP_WRITE, buf);</span><br><span class="line">                        wait = <span class="keyword">false</span>;</span><br><span class="line">                    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.isWritable()) &#123;</span><br><span class="line">                        ByteBuffer buf = (ByteBuffer) key.attachment();</span><br><span class="line">                        SocketChannel channel = (SocketChannel) key.channel();</span><br><span class="line">                        buf.clear();</span><br><span class="line">                        buf.put(<span class="keyword">new</span> String(msg).getBytes(<span class="string">"UTF-8"</span>));</span><br><span class="line">                        buf.flip();</span><br><span class="line">                        <span class="keyword">while</span> (buf.hasRemaining()) &#123;</span><br><span class="line">                            channel.write(buf);</span><br><span class="line">                        &#125;</span><br><span class="line">                        buf.compact();</span><br><span class="line">                        channel.register(selector, SelectionKey.OP_READ, buf);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    selector.close();</span><br><span class="line">                    client.close();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                    e1.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> NioSocketClient().connect();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/17/java/nio的ByteBuffer、Channel和Selector详解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/17/java/nio的ByteBuffer、Channel和Selector详解/" itemprop="url">nio的ByteBuffer、Channel和Selector详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-17T00:00:00+08:00">
                2017-10-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index">
                    <span itemprop="name">java</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="NIO概述"><a href="#NIO概述" class="headerlink" title="NIO概述"></a>NIO概述</h1><p>传统IO是阻塞的，比如当服务端执行<code>serverSocket.accept()</code>的时候，就会一直阻塞在这里，当有客户端连接进来时，阻塞才会被唤醒，然后为新进来的连接启动一个线程去处理单独的客户端请求。</p>
<p>而且传统IO是基于socket的输入输出流的，比如当服务端调用<code>socket().getInputStream().read()</code>读取客户端数据时，如果客户端迟迟不发送数据(比如因为网络延迟等等原因)，服务端线程就会一直阻塞在这里。</p>
<p>当客户端连接非常多的时候，服务端就开启了大量线程，而每一个线程在jvm中都要占用不少内存，并且服务端CPU在各个线程中切换时，又会耗费很多性能，所以传统的IO方式对于客户端数量非常多的情形就不太适用。于是jdk中就引入了NIO的实现弥补传统IO在某些应用场景的不足。</p>
<p>我觉得NIO是对传统IO的补充，并不能取代传统IO，传统IO在用户量小并且单个连接传输数据量较大的时候比NIO更有优势。</p>
<p>关于NIO有几个核心概念，Buffer、Channel、Selector。</p>
<h1 id="ByteBuffer详解"><a href="#ByteBuffer详解" class="headerlink" title="ByteBuffer详解"></a>ByteBuffer详解</h1><p>相对于传统IO是基于输入输出流的来言，NIO是基于Buffer的。NIO中Buffer的具体的实现有很多，比如ByteBuffer、LongBuffer、IntBuffer等，这里只讲最重要的ByteBuffer。</p>
<p>ByteBuffer内部有几个指针非常重要，读写数据全靠这些指针来标识。如下图所示：<br><img src="/images/hadoop/buffers-modes.png" alt=""> </p>
<h2 id="capacity"><a href="#capacity" class="headerlink" title="capacity"></a>capacity</h2><p>对于ByteBuffer来说，capacity相当于其容量，最多只能向其中写入capacity个byte，如果写满之后，就再也写不进去了。</p>
<h2 id="position"><a href="#position" class="headerlink" title="position"></a>position</h2><p>初始的position值为0，当用户写入一个byte时，position就变为了1，position最大为capacity-1。不仅向ByteBuffer中写数据会改变position，从其中读数据也会改变position。</p>
<h2 id="limit"><a href="#limit" class="headerlink" title="limit"></a>limit</h2><p>limit像是一堵墙卡在那里，标识着用户最多能读到limit位置或者最多能写多少字节。</p>
<p>想用好ByteBuffer就必须要深刻理解上述的3个标识变量，因为ByteBuffer的很多个API方法都是在操作这3个变量，ByteBuffer就是根据这3个指针来控制读写。</p>
<p>下面就介绍一些ByteBuffer中非常常用的方法：</p>
<p>首先是生成ByteBuffer。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 生成一个capacity为48的buf</span></span><br><span class="line">ByteBuffer buf = ByteBuffer.allocate(<span class="number">48</span>);</span><br><span class="line"><span class="comment">// 也可以根据已有的byte[]来创建，这样的话，就将b这个数组“绑定”到了buf上，需要注意的是，当数组b内容变化时，buf中数据也会变化</span></span><br><span class="line"><span class="keyword">byte</span>[] b = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">48</span>];</span><br><span class="line">ByteBuffer buf = ByteBuffer.warp(b);</span><br></pre></td></tr></table></figure></p>
<p>然后是ByteBuffer的一些读写常用的方法：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 一般情况下，在向ByteBuffer中写入数据之前都要先clear下，将buf“清空”，其实可以看到数据并没有清空，只是改变了内部的指针位置</span></span><br><span class="line"><span class="comment">// 所以可以将clear方法看做是将Buf切换到写模式</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    limit = capacity;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 当buf中写完数据后，准备读数据之前，需要调用flip方法来切换到读模式</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">flip</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    limit = position;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// rewind方法只是简单将position = 0，有时候也会用到此方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">rewind</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 这个方法可以用来获取buf中未读的数据的长度，也很常用，比如根据bytebuffer的长度创建一个byte[] b = new byte[buf.remaining()]</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">remaining</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> limit - position;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这个方法经常用来判断buf中是否还有数据未读取完</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">hasRemaining</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> position &lt; limit;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// compact方法相对来说是这些方法中最难理解的一个，下面重点说一下</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ByteBuffer <span class="title">compact</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.arraycopy(hb, ix(position()), hb, ix(<span class="number">0</span>), remaining());</span><br><span class="line">    position(remaining());</span><br><span class="line">    limit(capacity());</span><br><span class="line">    discardMark();</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>从上述代码中可以看到，compact方法是将从position位置，一直到limit-1位置的这些字节数据，copy到0的位置，然后讲position = limit - position，并将limit置为capacity。</p>
<p>也就是说，如果remaining()为0的情况下，compact的效果几乎等同于clear。下图可以很清晰的展示compact方法：</p>
<p>执行compact之前:<br><img src="/images/hadoop/compact1.jpg" alt=""> </p>
<p>compact后<br><img src="/images/hadoop/compact2.jpg" alt=""> </p>
<p>一般什么时候会用到compact方法呢？一般是在write的时候，因为很多时候write方法并不能一次性将ByteBuffer中的数据读取完，如果直接clear的话，那么当新数据写入时，之前未读完的数据就会被覆盖。所以此时可以在write之后调用compact，将未读完的数据copy的buffer的0位置处，然后新数据就会在老数据后面的位置开始写，之前的数据就不会被覆盖。</p>
<h1 id="Channel详解"><a href="#Channel详解" class="headerlink" title="Channel详解"></a>Channel详解</h1><p>Channel就好像传统IO中的输入输出流，只不过传统IO的输入输出流是按字节或字符读取或写入数据，而Channel是操作的ByteBuffer。</p>
<p>Channel的实现有FileChannel、SocketChannel、ServerSocketChannel、DatagramChannel。其中，FileChannel可以从文件中读写数据，SocketChannel能通过TCP读写数据，ServerSocketChannel可以监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。</p>
<p>下面通过一个copy文件的例子来更好的理解和运用Channel和ByteBuffer。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">CopyFile</span><span class="params">(String srcPath, String dstPath)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">     <span class="comment">//建立file的输入输出流</span></span><br><span class="line">     FileInputStream infs = <span class="keyword">new</span> FileInputStream(srcPath);</span><br><span class="line">     FileOutputStream outfs = <span class="keyword">new</span> FileOutputStream(dstPath);</span><br><span class="line">     <span class="comment">//通过file流获得nio的channel</span></span><br><span class="line">     FileChannel inc = infs.getChannel();</span><br><span class="line">     FileChannel outc = outfs.getChannel();</span><br><span class="line"></span><br><span class="line">     <span class="comment">//创建一个用于nio传输数据的buffer</span></span><br><span class="line">     ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">     <span class="comment">//len表示从channel中读到buf的长度</span></span><br><span class="line">     <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">     <span class="keyword">while</span> ((len = inc.read(buf)) != -<span class="number">1</span>) &#123;    <span class="comment">//向buf里面写数据</span></span><br><span class="line">         <span class="comment">/*</span></span><br><span class="line"><span class="comment">             此时buf已经写入了数据，buf内部position指针已经置于len长度位置</span></span><br><span class="line"><span class="comment">             所以如果需要将buf中的数据读出来并写入到另外一个文件中时，就需要调用buf.flip()</span></span><br><span class="line"><span class="comment">             将limit = position; position = 0</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">         buf.flip();</span><br><span class="line">         <span class="comment">/*</span></span><br><span class="line"><span class="comment">             由于outc.write无法保证一次性将buf中的数据读取完，所以不能直接clear</span></span><br><span class="line"><span class="comment">             此处使用buf.hasRemaining()判断是否有未读取完的数据，如果有就继续读</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">         <span class="keyword">while</span> (buf.hasRemaining()) &#123;</span><br><span class="line">             outc.write(buf);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">/*</span></span><br><span class="line"><span class="comment">             跳出while循环后，说明buf中的数据以及完全被读取，所以可以使用clear将buf中指针置为写模式</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">         buf.clear();</span><br><span class="line">     &#125;</span><br><span class="line">     outc.close();</span><br><span class="line">     inc.close();</span><br><span class="line">     outfs.close();</span><br><span class="line">     infs.close();</span><br><span class="line">     System.out.println(<span class="string">"finished!"</span>);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>上面是使用while循环+clear的方式来确保数据的读写正确，下面介绍使用compact方式来读写数据:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">copy</span><span class="params">(ReadableByteChannel src, WritableByteChannel des)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">        <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>((len = src.read(buf)) != -<span class="number">1</span>)&#123; <span class="comment">//向buf里面写数据</span></span><br><span class="line">            <span class="comment">// 写完数据后，切换到读模式开始读取buf中的数据</span></span><br><span class="line">            buf.flip();</span><br><span class="line">            des.write(buf);</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">                由于outc.write无法保证一次性将buf中的数据读取完，所以不能直接clear</span></span><br><span class="line"><span class="comment">                调用compact方法将未读完的数据copy的buf的起始位置等待数据写入</span></span><br><span class="line"><span class="comment">            */</span></span><br><span class="line">            buf.compact();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">            可能会有朋友疑问这里为什么还要在执行一次读？其实是有必要的!我们考虑这样一种情况：</span></span><br><span class="line"><span class="comment">            当上面的while循环最后一次执行src.read(buf)，将文件最后的内容写入到buf中，假设此时des.write(buf)刚好没有将buf完全读取完</span></span><br><span class="line"><span class="comment">            然后就执行了buf.compact()，由于文件已经读取完，所以再次src.read(buf)=-1，那么就不会再进入while循环</span></span><br><span class="line"><span class="comment">            那么岂不是还有一些字节还未读完吗？所以下面的读取就是为了防止这种情况发送，确保将数据一个字节不差的读取完整        </span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        buf.flip();</span><br><span class="line">        <span class="keyword">while</span>(buf.hasRemaining())&#123;</span><br><span class="line">            des.write(buf);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h1><p>在NIO中Selector就好像一个大管家，NIO之所以可以做到非阻塞，就是源于Selector。这个Selector会不断的轮训检测，当有客户端连接、有客户端数据传送过来后，Selector就会收到通知，然后我们就可以进行相关操作。</p>
<p>要想使用Selector，就必须将channel设置为非阻塞模式，所以前面介绍的FileChannel就无法使用Selector，因为FileChannel无法设置为非阻塞，而SocketChannel和ServerSocketChannel都是可以设置为非阻塞的！</p>
<p>要想使用Selector，就要先创建。为了将Channel和Selector配合使用，必须将channel注册到selector上。通过<code>SelectableChannel.register()</code>方法来实现<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Selector selector = Selector.open();</span><br><span class="line">channel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">SelectionKey key = channel.register(selector,Selectionkey.OP_READ);</span><br></pre></td></tr></table></figure></p>
<p>上述代码具体有什么作用呢？首先使用Selector的open静态方法创建了Selector，然后将channel设置为非阻塞模式，然后将channel注册到selector上，并且告诉selector这个channel对OP_READ感兴趣！</p>
<p>意思就是：当这个channel上一旦有数据可读，系统就会通知正在不断轮训检测的Selector，然后我们程序员就可以写相关代码读取channel上的数据并进行相关处理。</p>
<p>一个Selector可以管理很多个channel，一个channel就好比传统IO中的一个客户端连接，用户客户端和服务端之间进行通信(具体管理多少个合适我也不是很懂= =！)，每个channel都可以向Selector注册自己感兴趣的事件，一旦这个channel上有感兴趣的事件来了，Selector就会收到通知。</p>
<p>channel向selector注册时还可以附件一些信息，比如:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">buf.put(<span class="string">"你好！"</span>.getBytes(<span class="string">"UTF-8"</span>));</span><br><span class="line">client.register(selector, SelectionKey.OP_READ, buf);</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/15/spark/spark集群安装与部署/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/15/spark/spark集群安装与部署/" itemprop="url">spark集群安装与部署</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-15T00:00:00+08:00">
                2017-10-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="安装scala"><a href="#安装scala" class="headerlink" title="安装scala"></a>安装scala</h1><p>这里同样准备三台机器node0、node1、node2来部署spark集群。安装spark之前，需要先安装scala环境。</p>
<p>下载scala安装包，这里采用的是scala-2.12.4版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://www.scala-lang.org/files/archive/scala-2.12.4.tgz</span><br><span class="line"></span><br><span class="line">tar zxf scala-2.12.4.tgz -C /usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure>
<p>配置环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/scala-2.12.4</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SCALA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line">scp /etc/profile node1:/etc</span><br><span class="line">scp /etc/profile node2:/etc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在三台机器上同时重读配置文件</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></p>
<p>分发安装包<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r scala-2.12.4/ node1:/usr/<span class="built_in">local</span>/</span><br><span class="line">scp -r scala-2.12.4/ node2:/usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure></p>
<h1 id="安装spark"><a href="#安装spark" class="headerlink" title="安装spark"></a>安装spark</h1><p>spark可以直接从hdfs或者hbase中读数据，所以如果需要从hdfs或hbase读取数据的话，还需要配置hadoop集群和hbase集群。三台机器上运行的进程如下:</p>
<p>node0 -&gt; namenode   resourcemanager     Master      Worker      HMaster<br>node1 -&gt; datanode   nodemanager     Worker  HRegionServer<br>node2 -&gt; datanode   nodemanager     Worker  HRegionServer</p>
<p>这里采用的是spark2.1.2，基于hadoop2.6的版本，先去官网下载安装包。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.1.2/spark-2.1.2-bin-hadoop2.6.tgz</span><br><span class="line"></span><br><span class="line">tar zxf spark-2.1.2-bin-hadoop2.6.tgz -C /usr/<span class="built_in">local</span></span><br></pre></td></tr></table></figure></p>
<p>配置环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark-2.1.2-bin-hadoop2.6</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$SPARK_HOME</span>/sbin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line">scp /etc/profile node1:/etc</span><br><span class="line">scp /etc/profile node2:/etc</span><br><span class="line"><span class="comment"># 在三台机器上同时重读配置文件</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></p>
<p>修改配置文件:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark-2.1.2-bin-hadoop2.6/conf</span><br><span class="line">cp slaves.template slaves</span><br><span class="line"><span class="comment"># 指定哪些节点为worker</span></span><br><span class="line">vim slaves</span><br><span class="line">node0</span><br><span class="line">node1</span><br><span class="line">node2</span><br><span class="line"></span><br><span class="line">cp spark-env.sh.template spark-env.sh</span><br><span class="line">vim spark-env.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_HOST=node0  <span class="comment">#指定master</span></span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_PORT=7077   <span class="comment">#指定master端口</span></span><br><span class="line"><span class="built_in">export</span> SPARK_WORKER_INSTANCES=1 <span class="comment">#指定每个节点运行的worker进程数量</span></span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_WEBUI_PORT=8080 <span class="comment">#webui界面端口</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.8.0_161/   <span class="comment">#最好指定下JAVA_HOME，不然使用start-all.sh脚本启动时读不到JAVA_HOME</span></span><br></pre></td></tr></table></figure></p>
<p>分发安装包<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r spark-2.1.2-bin-hadoop2.6/ node1:/usr/<span class="built_in">local</span>/</span><br><span class="line">scp -r spark-2.1.2-bin-hadoop2.6/ node2:/usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure></p>
<p>启动spark集群<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-all.sh</span><br></pre></td></tr></table></figure></p>
<p>然后可以在各节点上使用jps查看是否启动成功，也可以在浏览器访问<a href="http://node0:8080来查看spark集群的web页面。启动spark-shell环境：" target="_blank" rel="noopener">http://node0:8080来查看spark集群的web页面。启动spark-shell环境：</a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-shell --master spark://node0:7077</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/14/storm/storm系列二-storm初体验之wordcount程序编写/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/14/storm/storm系列二-storm初体验之wordcount程序编写/" itemprop="url">storm系列二:storm初体验之wordcount程序编写</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-14T00:00:00+08:00">
                2017-10-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>上一篇文章中我们进行了storm集群的安装部署，并启动了storm集群，这篇文章，我们写一个最简单的wordcount的示例程序。</p>
<h2 id="项目依赖"><a href="#项目依赖" class="headerlink" title="项目依赖"></a>项目依赖</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.storm<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>storm-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="Topology编写"><a href="#Topology编写" class="headerlink" title="Topology编写"></a>Topology编写</h2><p>在storm中，被提交的任务称为Topology，每一个storm任务都应该有一个Topology主驱动类，用来设置当前storm的并发度和数据执行流程等信息。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TopologyMain</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">        <span class="comment">// 设置数据源，一般情况下数据源有很多种，比如kafka消息队列等，这里采用比较简单的随机字符串，并设置2个并发度</span></span><br><span class="line">        builder.setSpout(<span class="string">"strings"</span>, <span class="keyword">new</span> RandomStringSpout(),<span class="number">2</span>);</span><br><span class="line">        <span class="comment">// shuffleGrouping("strings")表示从strings这个spout随机拉取数据到多个并行度的splitBolt中</span></span><br><span class="line">        builder.setBolt(<span class="string">"splitBolt"</span>, <span class="keyword">new</span> SplitBolt(),<span class="number">4</span>).shuffleGrouping(<span class="string">"strings"</span>);</span><br><span class="line">        <span class="comment">// fieldsGrouping("splitBolt",new Fields("word")) 表示按字段(hashCode)从上游bolt(splitBolt)中拉取数据</span></span><br><span class="line">        <span class="comment">// 由于是字段的hashCode，所以相同的单词必定会被传输到同一个wordCountBolt中</span></span><br><span class="line">        <span class="comment">// 每一个spout、bolt都可以emit多个字段，word表示wordCountBolt按照splitBolt的word字段从splitBolt拉取数据</span></span><br><span class="line">        builder.setBolt(<span class="string">"wordCountBolt"</span>,<span class="keyword">new</span> WorldCountBolt(),<span class="number">4</span>).fieldsGrouping(<span class="string">"splitBolt"</span>,<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">        <span class="comment">// storm程序可以在本地启动，也可以打成jar包使用 bin/storm jar xxx.jar mainclass的命令在storm集群上运行</span></span><br><span class="line">        <span class="comment">// 集群模式启动</span></span><br><span class="line">        Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">        <span class="comment">// 设置4个worker数量，一个worker可以认为就是一个jvm。</span></span><br><span class="line">        <span class="comment">// 前一篇文章中，我们部署的storm集群有2个supervisor节点，所以每个supervisor节点上面要启动2个worker进程</span></span><br><span class="line">        conf.setNumWorkers(<span class="number">4</span>);</span><br><span class="line">        StormSubmitter.submitTopologyWithProgressBar(<span class="string">"wordcount"</span>,conf,builder.createTopology());</span><br><span class="line">        <span class="comment">// 本地模式启动</span></span><br><span class="line">        <span class="comment">//conf.setMaxTaskParallelism(3);</span></span><br><span class="line">        <span class="comment">//LocalCluster cluster = new LocalCluster();</span></span><br><span class="line">        <span class="comment">//cluster.submitTopology("word-count", conf, builder.createTopology());</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="spout编写"><a href="#spout编写" class="headerlink" title="spout编写"></a>spout编写</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RandomStringSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> SpoutOutputCollector collector;</span><br><span class="line">    <span class="keyword">private</span> Random rand;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map map, TopologyContext topologyContext, SpoutOutputCollector spoutOutputCollector)</span> </span>&#123;</span><br><span class="line">        collector = spoutOutputCollector;</span><br><span class="line">        rand = <span class="keyword">new</span> Random();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String[] strs = <span class="keyword">new</span> String[]&#123;</span><br><span class="line">          <span class="string">"hello world"</span>,<span class="string">"hello ygq hello tom"</span>,</span><br><span class="line">          <span class="string">"my name is ygq"</span>,<span class="string">"what is your name"</span></span><br><span class="line">        &#125;;</span><br><span class="line">        String str = strs[rand.nextInt(strs.length)];</span><br><span class="line">        <span class="comment">// 将随机的某个字符串发射到下游bolt中</span></span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(str));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer outputFieldsDeclarer)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 表示这个spout发出的数据字段叫line</span></span><br><span class="line">        outputFieldsDeclarer.declare(<span class="keyword">new</span> Fields(<span class="string">"line"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="bolt编写"><a href="#bolt编写" class="headerlink" title="bolt编写"></a>bolt编写</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SplitBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        collector = outputCollector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 从tuple中取出spout中的line字段的数据，上游spout有可能发出了多个字段，不过本例中spout只发了一个字段line</span></span><br><span class="line">        String line = tuple.getStringByField(<span class="string">"line"</span>);</span><br><span class="line">        String[] words = line.split(<span class="string">" "</span>);</span><br><span class="line">        <span class="keyword">for</span>(String word : words)&#123;</span><br><span class="line">            <span class="comment">// 将切分后的单词发射到下游bolt</span></span><br><span class="line">            collector.emit(<span class="keyword">new</span> Values(word));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer outputFieldsDeclarer)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 表示这个bolt发出的数据字段叫word</span></span><br><span class="line">        outputFieldsDeclarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WorldCountBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">        这个map用来存每个单词的数量，这里用map来存储其实值得商榷，主要需要考虑几个问题：</span></span><br><span class="line"><span class="comment">            1. 有可能是多个WorldCountBolt线程在同一个worker进程内，那么这个map会不会有线程安全问题？</span></span><br><span class="line"><span class="comment">            其实，由于是根据字段分组fieldsGrouping，所以相同的word必然分配到了相同的WorldCountBolt</span></span><br><span class="line"><span class="comment">            所以在多个线程同时对这个map进行操作时，操作的其实是不同的key，所以是线程安全的</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">            2. 多个WorldCountBolt线程也有可能是运行在多个worker进程中的，甚至可能是运行在多台节点上，</span></span><br><span class="line"><span class="comment">            那么多个WorldCountBolt线程操作的map压根就不在一个进程内，压根就不是同一个map对象，</span></span><br><span class="line"><span class="comment">            所以每个WorldCountBolt线程的map的数据都不完整(但相同单词的个数是正确的)，</span></span><br><span class="line"><span class="comment">            需要将不同进程内的多个map拼接起来才是完整的结果</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">            3. 这里只是为了简单演示才使用了map这种数据结构，一般情况下，可以将计算结果存储到外部介质比如redis</span></span><br><span class="line"><span class="comment">    */</span>   </span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        collector = outputCollector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        String word = tuple.getStringByField(<span class="string">"word"</span>);</span><br><span class="line">        <span class="keyword">if</span>(map.containsKey(word))&#123;</span><br><span class="line">            Integer count = map.get(word);</span><br><span class="line">            count++;</span><br><span class="line">            map.put(word,count);</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            map.put(word,<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(Thread.currentThread().getName()+<span class="string">" "</span>+map);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer outputFieldsDeclarer)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 由于没有下游bolt了，所以声不声明输出字段都无所谓了</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/13/storm/storm系列一-storm集群安装部署/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/13/storm/storm系列一-storm集群安装部署/" itemprop="url">storm系列一:storm集群安装部署</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-13T00:00:00+08:00">
                2017-10-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>参照storm官网，storm集群部署主要分为一下几步：</p>
<ol>
<li>部署zookeeper集群。storm集群重度依赖zk，用zk来记录很多信息，所以部署storm集群之前要先部署好zk集群</li>
<li>下载安装包并解压到storm集群各节点上</li>
<li>修改各节点的配置文件</li>
<li>使用storm提供的脚本启动storm集群</li>
</ol>
<h1 id="集群安装部署"><a href="#集群安装部署" class="headerlink" title="集群安装部署"></a>集群安装部署</h1><h2 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h2><p>一共使用三台机器，分别是node0、node1、node2，这三台机器上也部署了zk服务端，使用node0作为nimbus，其他两台机器作为supervisor用来启动work。</p>
<p>这里采用的storm安装版本是apache-storm-1.2.1。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar zxf apache-storm-1.2.1.tar.gz -C /usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure>
<p>修改配置文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/apache-storm-1.2.1/conf</span><br><span class="line">vim storm-env.sh </span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.8.0_161/</span><br><span class="line"><span class="comment"># 将原有配置文件备份一份</span></span><br><span class="line">cp storm.yaml&#123;,.bak&#125;</span><br><span class="line">vim storm.yaml </span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置zk集群</span></span><br><span class="line">storm.zookeeper.servers:</span><br><span class="line">     - <span class="string">"node0"</span></span><br><span class="line">     - <span class="string">"node1"</span></span><br><span class="line">     - <span class="string">"node2"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置nimbus节点</span></span><br><span class="line"> nimbus.seeds: [<span class="string">"node0"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Nimbus和Supervisor 用来存放jar和conf等文件的目录</span></span><br><span class="line"> storm.local.dir: <span class="string">"/var/storm_data"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每一个端口对应一个work进程，代表这个supervisor在本机器上最多启用多少个work，以及占用哪些端口</span></span><br><span class="line"> supervisor.slots.ports:</span><br><span class="line">    - 6700</span><br><span class="line">    - 6701</span><br><span class="line">    - 6702</span><br><span class="line">    - 6703</span><br><span class="line"></span><br><span class="line">scp -r apache-storm-1.2.1/ node1:/usr/<span class="built_in">local</span>/</span><br><span class="line">scp -r apache-storm-1.2.1/ node2:/usr/<span class="built_in">local</span>/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在每一台机器上创建数据目录</span></span><br><span class="line">mkdir -p /var/storm_data</span><br></pre></td></tr></table></figure></p>
<p>要注意storm.yaml配置文件中配置项中的空格，格式必须正确，否则可能启动失败</p>
<h2 id="启动storm集群"><a href="#启动storm集群" class="headerlink" title="启动storm集群"></a>启动storm集群</h2><p>在node0上启动Nimbus<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/storm nimbus &amp;&gt; /dev/null &amp;</span><br></pre></td></tr></table></figure></p>
<p>在node1和node2上启动supervisor<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/storm supervisor  &amp;&gt; /dev/null &amp;</span><br></pre></td></tr></table></figure></p>
<p>在node1上启动storm ui服务，可以在浏览器里查看storm集群的运行情况<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/storm ui  &amp;&gt; /dev/null &amp;</span><br></pre></td></tr></table></figure></p>
<p>然后在浏览器中输入: <a href="http://node1:8080即可查看storm集群的运行状态" target="_blank" rel="noopener">http://node1:8080即可查看storm集群的运行状态</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/11/web架构/hbase集群部署与基本使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/11/web架构/hbase集群部署与基本使用/" itemprop="url">hbase集群部署与基本使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-11T00:00:00+08:00">
                2017-10-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="hbase安装部署"><a href="#hbase安装部署" class="headerlink" title="hbase安装部署"></a>hbase安装部署</h1><h2 id="解压安装"><a href="#解压安装" class="headerlink" title="解压安装"></a>解压安装</h2><p>这里使用的是1.4.2版本的hbase，可以去官网下载habse安装包，下载后进行解压<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf hbase-1.4.2-bin.tar.gz -C /usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure></p>
<p>为了减少scp时间，可以将一些无用文件删掉<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/hbase-1.4.2</span><br><span class="line">rm -rf docs/ *.txt</span><br></pre></td></tr></table></figure></p>
<p>hbase分为HMaster和HRegionServer，其中HMaster主要管理元数据和HRegionServer的负载均衡等协调工作，而HRegionServer是客户端真正读写数据的地方，对于hbase集群来说，需要配置文件指定哪些是HRegionServer。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim conf/regionservers</span><br><span class="line"><span class="comment"># 将默认的localhost改为如下内容：</span></span><br><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>这里需要说明，一共有3台机器，node0为namenode和hmaster，node1和node2为datanode和regionserver。</p>
</blockquote>
<p>然后需要配置环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"export  HBASE_HOME=/usr/local/hbase-1.4.2"</span> &gt;&gt; /etc/profile</span><br><span class="line"></span><br><span class="line">vim conf/vim hbase-env.sh</span><br><span class="line"><span class="comment"># 填入自己的JAVA_HOME变量</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.8.0_161/</span><br><span class="line"><span class="comment"># 不使用hbase默认自带的zookeeper，而使用自己集群配置的zk</span></span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span></span><br></pre></td></tr></table></figure></p>
<p>修改hbase的核心配置文件hbase-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">　<span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!-- hbase存放数据目录 --&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!-- 指向hdfs的namenode路径--&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node0:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"> <span class="comment">&lt;!-- 是否分布式部署 --&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!-- zk地址 --&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>node0,node1,node2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span> 　　　</span><br><span class="line">　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--zookooper配置、日志等的存储位置 --&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>/var/hbase_zk_data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">　　<span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>分发安装包到其他节点:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r hbase-1.4.2/ node1:/usr/<span class="built_in">local</span>/</span><br><span class="line">scp -r hbase-1.4.2/ node2:/usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure></p>
<p>启动hbase集群，首先要确保hdfs集群和zk集群已启动<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/start-hbase.sh</span><br></pre></td></tr></table></figure></p>
<p>一定要注意的是，几个节点之间的时间一定要同步，否则master会认为一些不同步的regionserver已经挂掉而将其kill了。</p>
<h1 id="java-api操作habse"><a href="#java-api操作habse" class="headerlink" title="java api操作habse"></a>java api操作habse</h1><p>新版的hbase的api有很多变化，之前很多老版本的api已经废弃，这里采用的是hbase1.4.2版本的api，首先导入项目依赖<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.4.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="创建表和删除表"><a href="#创建表和删除表" class="headerlink" title="创建表和删除表"></a>创建表和删除表</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HBaseDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Admin admin;</span><br><span class="line">    <span class="keyword">private</span> Connection conn;</span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Before</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 创建config对象，主要是指定zk地址，因为zk里面记录着regionServer的地址，所以必须要连接zk，客户端才能知道去哪找regionServer</span></span><br><span class="line">        Configuration config = HBaseConfiguration.create();</span><br><span class="line">        config.set(<span class="string">"hbase.zookeeper.quorum"</span>, <span class="string">"node0,node1,node2"</span>);</span><br><span class="line">        config.set(<span class="string">"hbase.zookeeper.property.clientPort"</span>, <span class="string">"2181"</span>);</span><br><span class="line">        <span class="comment">// 通过config对象获取Connection连接对象</span></span><br><span class="line">        <span class="keyword">this</span>.conn = ConnectionFactory.createConnection(config);</span><br><span class="line">        <span class="comment">// 通过Connection对象获取Admin管理类的实例，Admin是一个接口，之前版本的HBaseAdmin实现类已经废弃</span></span><br><span class="line">        <span class="keyword">this</span>.admin = conn.getAdmin();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">CreateTable</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 创建表描述对象，表名为testTable，并向其中添加两个列族，分别是personInfo和companyInfo</span></span><br><span class="line">        HTableDescriptor htd = <span class="keyword">new</span> HTableDescriptor(TableName.valueOf(<span class="string">"testTable"</span>));</span><br><span class="line">        HColumnDescriptor hcd=<span class="keyword">new</span> HColumnDescriptor(<span class="string">"personInfo"</span>);</span><br><span class="line">        htd.addFamily(hcd);</span><br><span class="line">        HColumnDescriptor hcd2=<span class="keyword">new</span> HColumnDescriptor(<span class="string">"companyInfo"</span>);</span><br><span class="line">        htd.addFamily(hcd2);</span><br><span class="line">        <span class="comment">// 创建表</span></span><br><span class="line">        admin.createTable(htd);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">DeleteTable</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 删除表之前必须先disableTable</span></span><br><span class="line">        admin.disableTable(TableName.valueOf(<span class="string">"testTable2"</span>));</span><br><span class="line">        admin.deleteTable(TableName.valueOf(<span class="string">"testTable2"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="添加数据"><a href="#添加数据" class="headerlink" title="添加数据"></a>添加数据</h2><p>这里只列举添加单条数据，插入批量数据和插入单条几乎一样，只不过传入的是一个List<put><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">AddData</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Table table = conn.getTable(TableName.valueOf(<span class="string">"testTable"</span>));</span><br><span class="line">    <span class="comment">// 插入单条数据</span></span><br><span class="line">    Put row =<span class="keyword">new</span> Put(Bytes.toBytes(<span class="number">1</span>)); <span class="comment">//设置rowkey</span></span><br><span class="line">    <span class="comment">//向rowkey=1　的personInfo列族添加name=ygq 和 age=27</span></span><br><span class="line">    row.addColumn(Bytes.toBytes(<span class="string">"personInfo"</span>),Bytes.toBytes(<span class="string">"name"</span>),Bytes.toBytes(<span class="string">"ygq"</span>));</span><br><span class="line">    row.addColumn(Bytes.toBytes(<span class="string">"personInfo"</span>),Bytes.toBytes(<span class="string">"age"</span>),Bytes.toBytes(<span class="number">27</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//向rowkey=1　的companyInfo列族添加name=zondy 和 tel=58767</span></span><br><span class="line">    row.addColumn(Bytes.toBytes(<span class="string">"companyInfo"</span>),Bytes.toBytes(<span class="string">"name"</span>),Bytes.toBytes(<span class="string">"zondy"</span>));</span><br><span class="line">    row.addColumn(Bytes.toBytes(<span class="string">"companyInfo"</span>),Bytes.toBytes(<span class="string">"tel"</span>),Bytes.toBytes(<span class="string">"58767"</span>));</span><br><span class="line">    table.put(row);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></put></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/10/web架构/hdfs的namenode管理元数据机制/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/10/web架构/hdfs的namenode管理元数据机制/" itemprop="url">hdfs的管理元数据机制和RPC框架演示</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-10T00:00:00+08:00">
                2017-10-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="namenode元数据管理"><a href="#namenode元数据管理" class="headerlink" title="namenode元数据管理"></a>namenode元数据管理</h1><p>通过前面几篇博客的讲述，我们知道对于hdfs来说，namenode是至关重要的，客户端不管是上传还是下载文件，都要去namenode中寻找具体的block在哪些datanode上，所以如果namenode的元数据信息丢失，那对于hdfs集群来说是致命的。</p>
<p>既然如此，hdfs是如何管理自己的元数据不丢失的？</p>
<p>假设，用户新上传了一个文件到hdfs，那么namenode中是不是又多了一个元数据。那么这个元数据到底存在哪里？是直接写入磁盘吗？如果是直接写入磁盘，那么如果客户端非常多，大量上传文件时，性能必然很低。就好像mysql插入数据时一样，mysql也不是直接插入磁盘的，而是会先缓存在内存中，然后找一个时机在同步到磁盘里面持久化。</p>
<p>如果namenode将元数据写入内存，新的问题又来了，如果元数据全部保存在内存中的话，虽然性能提高了，但是如果namenode宕机了呢？元数据岂不是全部丢失了，这绝对是灾难。所以namenode必然要每隔一段时间就将元数据信息写入磁盘，以保证数据安全。</p>
<p>所以在前面博客中我们看到了在namenode中有类似于<code>fsimage_0000000000000000028</code>这种文件。这种文件其实就是将namenode元数据信息的内存对象dump(序列号)到磁盘文件。但问题是多久dump一次呢？如果每来一条新的元数据就dump一次肯定不合适，如果间隔太久肯定也不合适，因为假设间隔10分钟同步一次，那么这10分钟之内如果namenode挂了，那这10分钟的数据就丢失了。</p>
<p>由于上述的种种原因，所以hdfs中另一个角色secondary namenode出场了。secondary namenode的主要职责就是管理元数据的镜像文件，他们的工作机制如下图所示：</p>
<p><img src="/images/hadoop/元数据管理.png" alt=""> </p>
<p>每当有新的元数据更新请求时，namenode会先更新管理元数据的内存对象，然后不会写入磁盘，而是写入一个edits日志文件。上篇博客中，我们介绍了namenode的元数据目录结构，如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@ygq hdfsdata] tree</span><br><span class="line">.</span><br><span class="line">└── dfs</span><br><span class="line">    ├── name</span><br><span class="line">    │   ├── current</span><br><span class="line">    │   │   ├── edits_0000000000000000001-0000000000000000002</span><br><span class="line">    │   │   ├── edits_0000000000000000003-0000000000000000015</span><br><span class="line">    │   │   ├── edits_0000000000000000016-0000000000000000022</span><br><span class="line">    │   │   ├── edits_0000000000000000023-0000000000000000024</span><br><span class="line">    │   │   ├── edits_0000000000000000025-0000000000000000026</span><br><span class="line">    │   │   ├── edits_inprogress_0000000000000000027</span><br><span class="line">    │   │   ├── fsimage_0000000000000000024</span><br><span class="line">    │   │   ├── fsimage_0000000000000000024.md5</span><br><span class="line">    │   │   ├── fsimage_0000000000000000026</span><br><span class="line">    │   │   ├── fsimage_0000000000000000026.md5</span><br><span class="line">    │   │   ├── seen_txid</span><br><span class="line">    │   │   └── VERSION</span><br><span class="line">    │   └── in_use.lock</span><br><span class="line">    └── namesecondary</span><br><span class="line">        ├── current</span><br><span class="line">        │   ├── edits_0000000000000000001-0000000000000000002</span><br><span class="line">        │   ├── edits_0000000000000000003-0000000000000000015</span><br><span class="line">        │   ├── edits_0000000000000000016-0000000000000000022</span><br><span class="line">        │   ├── edits_0000000000000000023-0000000000000000024</span><br><span class="line">        │   ├── edits_0000000000000000025-0000000000000000026</span><br><span class="line">        │   ├── fsimage_0000000000000000024</span><br><span class="line">        │   ├── fsimage_0000000000000000024.md5</span><br><span class="line">        │   ├── fsimage_0000000000000000026</span><br><span class="line">        │   ├── fsimage_0000000000000000026.md5</span><br><span class="line">        │   └── VERSION</span><br><span class="line">        └── in_use.lock</span><br></pre></td></tr></table></figure></p>
<p>可以看到有一个个的edits文件。其中namesecondary就是secondary namenode。这里需要说明的是，一般情况下这两个目录不会在同一台服务器，这里只是由于实验环境为了节省机器，所以将secondary namenode和主namenode配置在同一台机器，正常情况下两者是分开的(HA集群下情况另算)。</p>
<p>通过上述结构，我们可以看出，edits日志文件也是可以滚动的，edits_inprogress代表正在写入的。</p>
<p>edits文件中记录的是什么呢？其实里面记录的是元数据的更新操作，是追加性写入(非常类似与mysql中的redo log)。那么如果有了edits文件，前面所提到的问题就解决了，比如假设上一次同步磁盘之后的某段时间namenode宕机，那再次启动namenode时就不会丢失数据，因为可以使用最新的fsimage+edits文件得到宕机前的所有数据。</p>
<p>但是这样有引入了新的问题，通过上面结构我们也看到了edits文件随着日积月累会越来越多，那么当namenode宕机再次启动时，岂不是要恢复很久？所以为了解决这个问题，就需要定期的将edits文件和fsimage文件合并，这样的话，namenode再次启动时，edits文件只有很小一部分需要合并，速度就会快很多。这个合并工作肯定不能归namenode自己去做，所以是有secondary namenode来进行合并的，基于此就引入了checkpoint机制。</p>
<h2 id="checkpoint机制"><a href="#checkpoint机制" class="headerlink" title="checkpoint机制"></a>checkpoint机制</h2><p>checkpoint触发是需要条件的，这些用户可以配置：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 检查触发条件是否满足的频率，60秒 --&gt;</span></span><br><span class="line">dfs.namenode.checkpoint.check.period=60  </span><br><span class="line">dfs.namenode.checkpoint.dir=file://$&#123;hadoop.tmp.dir&#125;/dfs/namesecondary</span><br><span class="line"><span class="comment">&lt;!-- 以上两个参数做checkpoint操作时，secondary namenode的本地工作目录 --&gt;</span></span><br><span class="line">dfs.namenode.checkpoint.edits.dir=$&#123;dfs.namenode.checkpoint.dir&#125;</span><br><span class="line"><span class="comment">&lt;!-- 最大重试次数 --&gt;</span></span><br><span class="line">dfs.namenode.checkpoint.max-retries=3  </span><br><span class="line"><span class="comment">&lt;!-- 两次checkpoint之间的时间间隔3600秒 --&gt;</span></span><br><span class="line">dfs.namenode.checkpoint.period=3600  </span><br><span class="line"><span class="comment">&lt;!-- 两次checkpoint之间最大的操作记录 --&gt;</span></span><br><span class="line">dfs.namenode.checkpoint.txns=1000000</span><br></pre></td></tr></table></figure></p>
<p>具体的流程如下：</p>
<ol>
<li>secondary namenode向namenode请求，询问是否需要进行checkpoint</li>
<li>namenode检查是否满足checkpoint条件，假设满足</li>
<li>secondary namenode发起checkpoint的请求</li>
<li>namenode立即滚动一次正在写的edit文件(edits_inprogress)</li>
<li>secondary namenode将namenode上的edit文件和fsimage文件下载到本地，并加载到内存进行合并，然后在dump成一个新的fsimage文件</li>
<li>secondary namenode将新的fsimage文件上传到namenode，覆盖原有fsimage文件</li>
</ol>
<h1 id="hadoop内部rpc框架使用"><a href="#hadoop内部rpc框架使用" class="headerlink" title="hadoop内部rpc框架使用"></a>hadoop内部rpc框架使用</h1><p>hadoop内部各节点之间通信都是通过rpc进行的，这里使用hadoop内部提供的rpc框架编写一个客户端调用服务端方法的例子。</p>
<p>首先服务端需要将待发布的服务封装成一个接口，我们来自定义这个接口:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">ClientNamenodeProtocol</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 这个versionID字段必须要有，而且名字必须是versionID</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> versionID = <span class="number">0L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getMetaData</span><span class="params">(String path)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>然后服务端需要写一个接口的实现类，并将其发布成服务，这里为了简便直接将服务端写成了实现类:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PublishService</span> <span class="keyword">implements</span> <span class="title">ClientNamenodeProtocol</span></span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 创建一个Builder，用来设置服务端信息</span></span><br><span class="line">        RPC.Builder builder = <span class="keyword">new</span> RPC.Builder(<span class="keyword">new</span> Configuration());</span><br><span class="line">        builder.setBindAddress(<span class="string">"127.0.0.1"</span>).setPort(<span class="number">1314</span>)   <span class="comment">// 绑定服务端ip和端口</span></span><br><span class="line">                .setProtocol(ClientNamenodeProtocol.class)  <span class="comment">// 设置服务端的协议，也就是服务接口</span></span><br><span class="line">                .setInstance(<span class="keyword">new</span> PublishService());         <span class="comment">// 设置实现类的实例</span></span><br><span class="line">        RPC.Server server = builder.build();</span><br><span class="line">        <span class="comment">// 启动服务端并发布服务</span></span><br><span class="line">        server.start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 服务端实现接口</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getMetaData</span><span class="params">(String path)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> path+<span class="string">"[blk_01,blk_02,blk_03] &#123;blk_01:node01,node02&#125;"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>至此，服务端就简单的将一个getMetaData的方法发布为服务，供其他节点去调用，剩下的就是客户端调用了:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 获取代理对象</span></span><br><span class="line">        ClientNamenodeProtocol proxy = RPC.getProxy(</span><br><span class="line">            ClientNamenodeProtocol.class,   <span class="comment">// 设置服务端的协议，也就是服务接口</span></span><br><span class="line">            <span class="number">0L</span>,                             <span class="comment">// 服务端协议的versionID</span></span><br><span class="line">            <span class="keyword">new</span> InetSocketAddress(<span class="string">"127.0.0.1"</span>, <span class="number">1314</span>), <span class="comment">// 服务端的ip和端口</span></span><br><span class="line">            <span class="keyword">new</span> Configuration());</span><br><span class="line">        <span class="comment">// 得到代理对象后，调用服务接口的方法，请求服务端</span></span><br><span class="line">        String metaData = proxy.getMetaData(<span class="string">"/input"</span>);</span><br><span class="line">        System.out.println(metaData);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">ygqqq</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">41</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/linux.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">37</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ygqqq</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
