<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="for the dream">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="for the dream">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="for the dream">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>for the dream</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">for the dream</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/18/java/基于NIO实现客户端与服务端聊天程序/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/18/java/基于NIO实现客户端与服务端聊天程序/" itemprop="url">基于NIO实现客户端与服务端聊天程序</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-18T00:00:00+08:00">
                2017-10-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index">
                    <span itemprop="name">java</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="服务端实现"><a href="#服务端实现" class="headerlink" title="服务端实现"></a>服务端实现</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NioSocketServer</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Selector selector;</span><br><span class="line">    <span class="keyword">private</span> ServerSocketChannel server;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> port = <span class="number">8080</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> TIME_OUT = <span class="number">3000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NioSocketServer</span><span class="params">(<span class="keyword">int</span> port)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.port = port;</span><br><span class="line">        server = ServerSocketChannel.open();</span><br><span class="line">        server.socket().bind(<span class="keyword">new</span> InetSocketAddress(port));</span><br><span class="line">        server.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        selector = Selector.open();</span><br><span class="line">        server.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ServerStart</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="comment">// 如果没有可用事件，selector.select(TIME_OUT)会阻塞TIME_OUT毫秒然后返回0，如果有可用事件则直接返回事件数量</span></span><br><span class="line">            <span class="keyword">int</span> evCount = selector.select(TIME_OUT);</span><br><span class="line">            <span class="keyword">if</span> (evCount == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="comment">// 所有channel向selector注册的事件都会在这里处理</span></span><br><span class="line">            Set&lt;SelectionKey&gt; keys = selector.selectedKeys();</span><br><span class="line">            Iterator&lt;SelectionKey&gt; it = keys.iterator();</span><br><span class="line">            <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">                SelectionKey key = it.next();</span><br><span class="line">                it.remove();</span><br><span class="line">                <span class="keyword">if</span> (key.isAcceptable()) &#123;</span><br><span class="line">                    handleAccept(key);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.isReadable()) &#123;</span><br><span class="line">                    handleRead(key);</span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.isWritable()) &#123;</span><br><span class="line">                    handleWrite(key);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleAccept</span><span class="params">(SelectionKey key)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 由于是isAcceptable类型的事件，所以key.channel得到的是ServerSocketChannel类型的channel，其实就是server</span></span><br><span class="line">        ServerSocketChannel ssc = (ServerSocketChannel) key.channel();</span><br><span class="line">        SocketChannel client = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            client = ssc.accept();</span><br><span class="line">            client.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">            System.out.println(client.socket().getRemoteSocketAddress() + <span class="string">"已连接..."</span>);</span><br><span class="line">            <span class="comment">// 当有客户端建立好连接后，向客户端发送欢迎信息</span></span><br><span class="line">            String welcome = client.socket().getRemoteSocketAddress() + <span class="string">"，你好，欢迎你！\n"</span>;</span><br><span class="line">            buf.put(welcome.getBytes(<span class="string">"UTF-8"</span>));</span><br><span class="line">            buf.flip();</span><br><span class="line">            <span class="keyword">while</span> (buf.hasRemaining()) &#123;</span><br><span class="line">                client.write(buf);</span><br><span class="line">            &#125;</span><br><span class="line">            buf.clear();</span><br><span class="line">            <span class="comment">//发送完信息后，将这个channel向selector注册一个读事件</span></span><br><span class="line">            <span class="comment">//当这个channel对应的客户端发来数据并且数据可读时，就会selector就会收到通知并放入selector.selectedKeys()中</span></span><br><span class="line">            client.register(selector, SelectionKey.OP_READ, buf);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (client != <span class="keyword">null</span>) client.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                e1.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleRead</span><span class="params">(SelectionKey key)</span> </span>&#123;</span><br><span class="line">        SocketChannel clientChannel = (SocketChannel) key.channel();</span><br><span class="line">        ByteBuffer buf = (ByteBuffer) key.attachment();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//　服务端打印收到的客户端发送来的数据</span></span><br><span class="line">            <span class="keyword">int</span> len = clientChannel.read(buf);</span><br><span class="line">            <span class="keyword">if</span> (len == -<span class="number">1</span> || len == <span class="number">0</span>) &#123;</span><br><span class="line">                clientChannel.close();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                String recMsg = <span class="keyword">new</span> String(buf.array(), <span class="number">0</span>, len);</span><br><span class="line">                System.out.println(clientChannel.socket().getRemoteSocketAddress() + <span class="string">"的数据:"</span> + recMsg);</span><br><span class="line">                buf.clear();</span><br><span class="line">                <span class="comment">// 打印完客户端发送来的信息之后，服务端想要给客户端回应</span></span><br><span class="line">                <span class="comment">//所以向buf中写入了一些信息，并注册OP_WRITE事件，但是注意此时并没有真正向客户端写(虽然此时可以写)</span></span><br><span class="line">                <span class="comment">//而是等待系统告知selector当前这个clientChannel以及可写后才真正去写</span></span><br><span class="line">                <span class="comment">//另外，当服务端向客户端写完之后，一定要取消注册OP_WRITE事件，因为每个channel一直都是可写状态</span></span><br><span class="line">                <span class="comment">//也就是说key.isWritable()返回的一直都是true，所以如果不取消OP_WRITE事件的话服务端就会一直向客户端发送数据</span></span><br><span class="line">                buf.put((<span class="string">"服务端已收到您发送的数据:"</span> + recMsg).getBytes(<span class="string">"UTF-8"</span>));</span><br><span class="line">                clientChannel.register(key.selector(), SelectionKey.OP_WRITE, buf);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (clientChannel != <span class="keyword">null</span>) clientChannel.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                e1.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleWrite</span><span class="params">(SelectionKey key)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//当channel可写时，用客户端发送数据</span></span><br><span class="line">        SocketChannel sc = (SocketChannel) key.channel();</span><br><span class="line">        ByteBuffer buf = (ByteBuffer) key.attachment();</span><br><span class="line">        buf.flip();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (buf.hasRemaining()) &#123;</span><br><span class="line">                sc.write(buf);</span><br><span class="line">            &#125;</span><br><span class="line">            buf.clear();</span><br><span class="line">            <span class="comment">// 写完数据之后，将OP_WRITE事件取消，并且注册OP_READ事件</span></span><br><span class="line">            sc.register(key.selector(), SelectionKey.OP_READ, buf);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (sc != <span class="keyword">null</span>) sc.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                e1.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> NioSocketServer(<span class="number">8555</span>).ServerStart();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="客户端实现"><a href="#客户端实现" class="headerlink" title="客户端实现"></a>客户端实现</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NioSocketClient</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> SocketChannel client;</span><br><span class="line">    <span class="keyword">private</span> Selector selector;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NioSocketClient</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            client = SocketChannel.open();</span><br><span class="line">            client.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            <span class="comment">//在非阻塞模式下，此时调用connect()，该方法可能在连接建立之前就返回了。为了确定连接是否建立，可以调用finishConnect()的方法</span></span><br><span class="line">            client.connect(<span class="keyword">new</span> InetSocketAddress(<span class="string">"127.0.0.1"</span>, <span class="number">8555</span>));</span><br><span class="line">            selector = Selector.open();</span><br><span class="line">            client.register(selector, SelectionKey.OP_CONNECT);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                selector.close();</span><br><span class="line">                client.close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                e1.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">connect</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (client.isConnectionPending()) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span>(client.finishConnect())&#123;</span><br><span class="line">                    client.register(selector, SelectionKey.OP_READ, ByteBuffer.allocate(<span class="number">1024</span>));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    selector.close();</span><br><span class="line">                    client.close();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                    e1.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">        <span class="keyword">while</span> (scanner.hasNextLine()) &#123;</span><br><span class="line">            String msg = scanner.nextLine();</span><br><span class="line">            <span class="keyword">if</span> (<span class="string">""</span>.equals(msg)) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"exit"</span>.equals(msg)) System.exit(<span class="number">0</span>);</span><br><span class="line">            <span class="keyword">else</span> handle(msg);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(String msg)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> wait = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">while</span> (wait) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">int</span> count = selector.select(<span class="number">3000</span>);</span><br><span class="line">                <span class="keyword">if</span> (count == <span class="number">0</span>) <span class="keyword">continue</span>;</span><br><span class="line">                Set&lt;SelectionKey&gt; keys = selector.selectedKeys();</span><br><span class="line">                Iterator&lt;SelectionKey&gt; it = keys.iterator();</span><br><span class="line">                <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">                    SelectionKey key = it.next();</span><br><span class="line">                    it.remove();</span><br><span class="line">                    <span class="keyword">if</span> (key.isReadable()) &#123;</span><br><span class="line">                        ByteBuffer buf = (ByteBuffer) key.attachment();</span><br><span class="line">                        SocketChannel channel = (SocketChannel) key.channel();</span><br><span class="line">                        buf.clear();</span><br><span class="line">                        channel.read(buf);</span><br><span class="line">                        buf.flip();</span><br><span class="line">                        <span class="keyword">byte</span>[] by = <span class="keyword">new</span> <span class="keyword">byte</span>[buf.remaining()];</span><br><span class="line">                        buf.get(by);</span><br><span class="line">                        System.out.println(<span class="string">"接收到服务端数据:"</span> + channel.socket().getRemoteSocketAddress() + <span class="keyword">new</span> String(by, <span class="string">"UTF-8"</span>));</span><br><span class="line">                        channel.register(selector, SelectionKey.OP_WRITE, buf);</span><br><span class="line">                        wait = <span class="keyword">false</span>;</span><br><span class="line">                    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.isWritable()) &#123;</span><br><span class="line">                        ByteBuffer buf = (ByteBuffer) key.attachment();</span><br><span class="line">                        SocketChannel channel = (SocketChannel) key.channel();</span><br><span class="line">                        buf.clear();</span><br><span class="line">                        buf.put(<span class="keyword">new</span> String(msg).getBytes(<span class="string">"UTF-8"</span>));</span><br><span class="line">                        buf.flip();</span><br><span class="line">                        <span class="keyword">while</span> (buf.hasRemaining()) &#123;</span><br><span class="line">                            channel.write(buf);</span><br><span class="line">                        &#125;</span><br><span class="line">                        buf.compact();</span><br><span class="line">                        channel.register(selector, SelectionKey.OP_READ, buf);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    selector.close();</span><br><span class="line">                    client.close();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IOException e1) &#123;</span><br><span class="line">                    e1.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> NioSocketClient().connect();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/17/java/nio的ByteBuffer、Channel和Selector详解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/17/java/nio的ByteBuffer、Channel和Selector详解/" itemprop="url">nio的ByteBuffer、Channel和Selector详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-17T00:00:00+08:00">
                2017-10-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index">
                    <span itemprop="name">java</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="NIO概述"><a href="#NIO概述" class="headerlink" title="NIO概述"></a>NIO概述</h1><p>传统IO是阻塞的，比如当服务端执行<code>serverSocket.accept()</code>的时候，就会一直阻塞在这里，当有客户端连接进来时，阻塞才会被唤醒，然后为新进来的连接启动一个线程去处理单独的客户端请求。</p>
<p>而且传统IO是基于socket的输入输出流的，比如当服务端调用<code>socket().getInputStream().read()</code>读取客户端数据时，如果客户端迟迟不发送数据(比如因为网络延迟等等原因)，服务端线程就会一直阻塞在这里。</p>
<p>当客户端连接非常多的时候，服务端就开启了大量线程，而每一个线程在jvm中都要占用不少内存，并且服务端CPU在各个线程中切换时，又会耗费很多性能，所以传统的IO方式对于客户端数量非常多的情形就不太适用。于是jdk中就引入了NIO的实现弥补传统IO在某些应用场景的不足。</p>
<p>我觉得NIO是对传统IO的补充，并不能取代传统IO，传统IO在用户量小并且单个连接传输数据量较大的时候比NIO更有优势。</p>
<p>关于NIO有几个核心概念，Buffer、Channel、Selector。</p>
<h1 id="ByteBuffer详解"><a href="#ByteBuffer详解" class="headerlink" title="ByteBuffer详解"></a>ByteBuffer详解</h1><p>相对于传统IO是基于输入输出流的来言，NIO是基于Buffer的。NIO中Buffer的具体的实现有很多，比如ByteBuffer、LongBuffer、IntBuffer等，这里只讲最重要的ByteBuffer。</p>
<p>ByteBuffer内部有几个指针非常重要，读写数据全靠这些指针来标识。如下图所示：<br><img src="/images/hadoop/buffers-modes.png" alt=""> </p>
<h2 id="capacity"><a href="#capacity" class="headerlink" title="capacity"></a>capacity</h2><p>对于ByteBuffer来说，capacity相当于其容量，最多只能向其中写入capacity个byte，如果写满之后，就再也写不进去了。</p>
<h2 id="position"><a href="#position" class="headerlink" title="position"></a>position</h2><p>初始的position值为0，当用户写入一个byte时，position就变为了1，position最大为capacity-1。不仅向ByteBuffer中写数据会改变position，从其中读数据也会改变position。</p>
<h2 id="limit"><a href="#limit" class="headerlink" title="limit"></a>limit</h2><p>limit像是一堵墙卡在那里，标识着用户最多能读到limit位置或者最多能写多少字节。</p>
<p>想用好ByteBuffer就必须要深刻理解上述的3个标识变量，因为ByteBuffer的很多个API方法都是在操作这3个变量，ByteBuffer就是根据这3个指针来控制读写。</p>
<p>下面就介绍一些ByteBuffer中非常常用的方法：</p>
<p>首先是生成ByteBuffer。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 生成一个capacity为48的buf</span></span><br><span class="line">ByteBuffer buf = ByteBuffer.allocate(<span class="number">48</span>);</span><br><span class="line"><span class="comment">// 也可以根据已有的byte[]来创建，这样的话，就将b这个数组“绑定”到了buf上，需要注意的是，当数组b内容变化时，buf中数据也会变化</span></span><br><span class="line"><span class="keyword">byte</span>[] b = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">48</span>];</span><br><span class="line">ByteBuffer buf = ByteBuffer.warp(b);</span><br></pre></td></tr></table></figure></p>
<p>然后是ByteBuffer的一些读写常用的方法：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 一般情况下，在向ByteBuffer中写入数据之前都要先clear下，将buf“清空”，其实可以看到数据并没有清空，只是改变了内部的指针位置</span></span><br><span class="line"><span class="comment">// 所以可以将clear方法看做是将Buf切换到写模式</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">clear</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    limit = capacity;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 当buf中写完数据后，准备读数据之前，需要调用flip方法来切换到读模式</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">flip</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    limit = position;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// rewind方法只是简单将position = 0，有时候也会用到此方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> Buffer <span class="title">rewind</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    position = <span class="number">0</span>;</span><br><span class="line">    mark = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 这个方法可以用来获取buf中未读的数据的长度，也很常用，比如根据bytebuffer的长度创建一个byte[] b = new byte[buf.remaining()]</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">remaining</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> limit - position;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这个方法经常用来判断buf中是否还有数据未读取完</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">hasRemaining</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> position &lt; limit;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// compact方法相对来说是这些方法中最难理解的一个，下面重点说一下</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> ByteBuffer <span class="title">compact</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    System.arraycopy(hb, ix(position()), hb, ix(<span class="number">0</span>), remaining());</span><br><span class="line">    position(remaining());</span><br><span class="line">    limit(capacity());</span><br><span class="line">    discardMark();</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>从上述代码中可以看到，compact方法是将从position位置，一直到limit-1位置的这些字节数据，copy到0的位置，然后讲position = limit - position，并将limit置为capacity。</p>
<p>也就是说，如果remaining()为0的情况下，compact的效果几乎等同于clear。下图可以很清晰的展示compact方法：</p>
<p>执行compact之前:<br><img src="/images/hadoop/compact1.jpg" alt=""> </p>
<p>compact后<br><img src="/images/hadoop/compact2.jpg" alt=""> </p>
<p>一般什么时候会用到compact方法呢？一般是在write的时候，因为很多时候write方法并不能一次性将ByteBuffer中的数据读取完，如果直接clear的话，那么当新数据写入时，之前未读完的数据就会被覆盖。所以此时可以在write之后调用compact，将未读完的数据copy的buffer的0位置处，然后新数据就会在老数据后面的位置开始写，之前的数据就不会被覆盖。</p>
<h1 id="Channel详解"><a href="#Channel详解" class="headerlink" title="Channel详解"></a>Channel详解</h1><p>Channel就好像传统IO中的输入输出流，只不过传统IO的输入输出流是按字节或字符读取或写入数据，而Channel是操作的ByteBuffer。</p>
<p>Channel的实现有FileChannel、SocketChannel、ServerSocketChannel、DatagramChannel。其中，FileChannel可以从文件中读写数据，SocketChannel能通过TCP读写数据，ServerSocketChannel可以监听新进来的TCP连接，像Web服务器那样。对每一个新进来的连接都会创建一个SocketChannel。</p>
<p>下面通过一个copy文件的例子来更好的理解和运用Channel和ByteBuffer。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">CopyFile</span><span class="params">(String srcPath, String dstPath)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">     <span class="comment">//建立file的输入输出流</span></span><br><span class="line">     FileInputStream infs = <span class="keyword">new</span> FileInputStream(srcPath);</span><br><span class="line">     FileOutputStream outfs = <span class="keyword">new</span> FileOutputStream(dstPath);</span><br><span class="line">     <span class="comment">//通过file流获得nio的channel</span></span><br><span class="line">     FileChannel inc = infs.getChannel();</span><br><span class="line">     FileChannel outc = outfs.getChannel();</span><br><span class="line"></span><br><span class="line">     <span class="comment">//创建一个用于nio传输数据的buffer</span></span><br><span class="line">     ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">     <span class="comment">//len表示从channel中读到buf的长度</span></span><br><span class="line">     <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">     <span class="keyword">while</span> ((len = inc.read(buf)) != -<span class="number">1</span>) &#123;    <span class="comment">//向buf里面写数据</span></span><br><span class="line">         <span class="comment">/*</span></span><br><span class="line"><span class="comment">             此时buf已经写入了数据，buf内部position指针已经置于len长度位置</span></span><br><span class="line"><span class="comment">             所以如果需要将buf中的数据读出来并写入到另外一个文件中时，就需要调用buf.flip()</span></span><br><span class="line"><span class="comment">             将limit = position; position = 0</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">         buf.flip();</span><br><span class="line">         <span class="comment">/*</span></span><br><span class="line"><span class="comment">             由于outc.write无法保证一次性将buf中的数据读取完，所以不能直接clear</span></span><br><span class="line"><span class="comment">             此处使用buf.hasRemaining()判断是否有未读取完的数据，如果有就继续读</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">         <span class="keyword">while</span> (buf.hasRemaining()) &#123;</span><br><span class="line">             outc.write(buf);</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="comment">/*</span></span><br><span class="line"><span class="comment">             跳出while循环后，说明buf中的数据以及完全被读取，所以可以使用clear将buf中指针置为写模式</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">         buf.clear();</span><br><span class="line">     &#125;</span><br><span class="line">     outc.close();</span><br><span class="line">     inc.close();</span><br><span class="line">     outfs.close();</span><br><span class="line">     infs.close();</span><br><span class="line">     System.out.println(<span class="string">"finished!"</span>);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>上面是使用while循环+clear的方式来确保数据的读写正确，下面介绍使用compact方式来读写数据:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">copy</span><span class="params">(ReadableByteChannel src, WritableByteChannel des)</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">        <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>((len = src.read(buf)) != -<span class="number">1</span>)&#123; <span class="comment">//向buf里面写数据</span></span><br><span class="line">            <span class="comment">// 写完数据后，切换到读模式开始读取buf中的数据</span></span><br><span class="line">            buf.flip();</span><br><span class="line">            des.write(buf);</span><br><span class="line">            <span class="comment">/*</span></span><br><span class="line"><span class="comment">                由于outc.write无法保证一次性将buf中的数据读取完，所以不能直接clear</span></span><br><span class="line"><span class="comment">                调用compact方法将未读完的数据copy的buf的起始位置等待数据写入</span></span><br><span class="line"><span class="comment">            */</span></span><br><span class="line">            buf.compact();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">            可能会有朋友疑问这里为什么还要在执行一次读？其实是有必要的!我们考虑这样一种情况：</span></span><br><span class="line"><span class="comment">            当上面的while循环最后一次执行src.read(buf)，将文件最后的内容写入到buf中，假设此时des.write(buf)刚好没有将buf完全读取完</span></span><br><span class="line"><span class="comment">            然后就执行了buf.compact()，由于文件已经读取完，所以再次src.read(buf)=-1，那么就不会再进入while循环</span></span><br><span class="line"><span class="comment">            那么岂不是还有一些字节还未读完吗？所以下面的读取就是为了防止这种情况发送，确保将数据一个字节不差的读取完整        </span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        buf.flip();</span><br><span class="line">        <span class="keyword">while</span>(buf.hasRemaining())&#123;</span><br><span class="line">            des.write(buf);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h1><p>在NIO中Selector就好像一个大管家，NIO之所以可以做到非阻塞，就是源于Selector。这个Selector会不断的轮训检测，当有客户端连接、有客户端数据传送过来后，Selector就会收到通知，然后我们就可以进行相关操作。</p>
<p>要想使用Selector，就必须将channel设置为非阻塞模式，所以前面介绍的FileChannel就无法使用Selector，因为FileChannel无法设置为非阻塞，而SocketChannel和ServerSocketChannel都是可以设置为非阻塞的！</p>
<p>要想使用Selector，就要先创建。为了将Channel和Selector配合使用，必须将channel注册到selector上。通过<code>SelectableChannel.register()</code>方法来实现<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Selector selector = Selector.open();</span><br><span class="line">channel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">SelectionKey key = channel.register(selector,Selectionkey.OP_READ);</span><br></pre></td></tr></table></figure></p>
<p>上述代码具体有什么作用呢？首先使用Selector的open静态方法创建了Selector，然后将channel设置为非阻塞模式，然后将channel注册到selector上，并且告诉selector这个channel对OP_READ感兴趣！</p>
<p>意思就是：当这个channel上一旦有数据可读，系统就会通知正在不断轮训检测的Selector，然后我们程序员就可以写相关代码读取channel上的数据并进行相关处理。</p>
<p>一个Selector可以管理很多个channel，一个channel就好比传统IO中的一个客户端连接，用户客户端和服务端之间进行通信(具体管理多少个合适我也不是很懂= =！)，每个channel都可以向Selector注册自己感兴趣的事件，一旦这个channel上有感兴趣的事件来了，Selector就会收到通知。</p>
<p>channel向selector注册时还可以附件一些信息，比如:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ByteBuffer buf = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">buf.put(<span class="string">"你好！"</span>.getBytes(<span class="string">"UTF-8"</span>));</span><br><span class="line">client.register(selector, SelectionKey.OP_READ, buf);</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/15/spark/spark集群安装与部署/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/15/spark/spark集群安装与部署/" itemprop="url">spark集群安装与部署</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-15T00:00:00+08:00">
                2017-10-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="安装scala"><a href="#安装scala" class="headerlink" title="安装scala"></a>安装scala</h1><p>这里同样准备三台机器node0、node1、node2来部署spark集群。安装spark之前，需要先安装scala环境。</p>
<p>下载scala安装包，这里采用的是scala-2.12.4版本。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://www.scala-lang.org/files/archive/scala-2.12.4.tgz</span><br><span class="line"></span><br><span class="line">tar zxf scala-2.12.4.tgz -C /usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure>
<p>配置环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/scala-2.12.4</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SCALA_HOME</span>/bin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line">scp /etc/profile node1:/etc</span><br><span class="line">scp /etc/profile node2:/etc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在三台机器上同时重读配置文件</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></p>
<p>分发安装包<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r scala-2.12.4/ node1:/usr/<span class="built_in">local</span>/</span><br><span class="line">scp -r scala-2.12.4/ node2:/usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure></p>
<h1 id="安装spark"><a href="#安装spark" class="headerlink" title="安装spark"></a>安装spark</h1><p>spark可以直接从hdfs或者hbase中读数据，所以如果需要从hdfs或hbase读取数据的话，还需要配置hadoop集群和hbase集群。三台机器上运行的进程如下:</p>
<p>node0 -&gt; namenode   resourcemanager     Master      Worker      HMaster<br>node1 -&gt; datanode   nodemanager     Worker  HRegionServer<br>node2 -&gt; datanode   nodemanager     Worker  HRegionServer</p>
<p>这里采用的是spark2.1.2，基于hadoop2.6的版本，先去官网下载安装包。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.1.2/spark-2.1.2-bin-hadoop2.6.tgz</span><br><span class="line"></span><br><span class="line">tar zxf spark-2.1.2-bin-hadoop2.6.tgz -C /usr/<span class="built_in">local</span></span><br></pre></td></tr></table></figure></p>
<p>配置环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark-2.1.2-bin-hadoop2.6</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$SPARK_HOME</span>/bin:<span class="variable">$SPARK_HOME</span>/sbin:<span class="variable">$PATH</span></span><br><span class="line"></span><br><span class="line">scp /etc/profile node1:/etc</span><br><span class="line">scp /etc/profile node2:/etc</span><br><span class="line"><span class="comment"># 在三台机器上同时重读配置文件</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></p>
<p>修改配置文件:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark-2.1.2-bin-hadoop2.6/conf</span><br><span class="line">cp slaves.template slaves</span><br><span class="line"><span class="comment"># 指定哪些节点为worker</span></span><br><span class="line">vim slaves</span><br><span class="line">node0</span><br><span class="line">node1</span><br><span class="line">node2</span><br><span class="line"></span><br><span class="line">cp spark-env.sh.template spark-env.sh</span><br><span class="line">vim spark-env.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_HOST=node0  <span class="comment">#指定master</span></span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_PORT=7077   <span class="comment">#指定master端口</span></span><br><span class="line"><span class="built_in">export</span> SPARK_WORKER_INSTANCES=1 <span class="comment">#指定每个节点运行的worker进程数量</span></span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_WEBUI_PORT=8080 <span class="comment">#webui界面端口</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.8.0_161/   <span class="comment">#最好指定下JAVA_HOME，不然使用start-all.sh脚本启动时读不到JAVA_HOME</span></span><br></pre></td></tr></table></figure></p>
<p>分发安装包<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r spark-2.1.2-bin-hadoop2.6/ node1:/usr/<span class="built_in">local</span>/</span><br><span class="line">scp -r spark-2.1.2-bin-hadoop2.6/ node2:/usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure></p>
<p>启动spark集群<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/start-all.sh</span><br></pre></td></tr></table></figure></p>
<p>然后可以在各节点上使用jps查看是否启动成功，也可以在浏览器访问<a href="http://node0:8080来查看spark集群的web页面。启动spark-shell环境：" target="_blank" rel="noopener">http://node0:8080来查看spark集群的web页面。启动spark-shell环境：</a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-shell --master spark://node0:7077</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/14/storm/storm系列二-storm初体验之wordcount程序编写/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/14/storm/storm系列二-storm初体验之wordcount程序编写/" itemprop="url">storm系列二:storm初体验之wordcount程序编写</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-14T00:00:00+08:00">
                2017-10-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>上一篇文章中我们进行了storm集群的安装部署，并启动了storm集群，这篇文章，我们写一个最简单的wordcount的示例程序。</p>
<h2 id="项目依赖"><a href="#项目依赖" class="headerlink" title="项目依赖"></a>项目依赖</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.storm<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>storm-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="Topology编写"><a href="#Topology编写" class="headerlink" title="Topology编写"></a>Topology编写</h2><p>在storm中，被提交的任务称为Topology，每一个storm任务都应该有一个Topology主驱动类，用来设置当前storm的并发度和数据执行流程等信息。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TopologyMain</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        TopologyBuilder builder = <span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">        <span class="comment">// 设置数据源，一般情况下数据源有很多种，比如kafka消息队列等，这里采用比较简单的随机字符串，并设置2个并发度</span></span><br><span class="line">        builder.setSpout(<span class="string">"strings"</span>, <span class="keyword">new</span> RandomStringSpout(),<span class="number">2</span>);</span><br><span class="line">        <span class="comment">// shuffleGrouping("strings")表示从strings这个spout随机拉取数据到多个并行度的splitBolt中</span></span><br><span class="line">        builder.setBolt(<span class="string">"splitBolt"</span>, <span class="keyword">new</span> SplitBolt(),<span class="number">4</span>).shuffleGrouping(<span class="string">"strings"</span>);</span><br><span class="line">        <span class="comment">// fieldsGrouping("splitBolt",new Fields("word")) 表示按字段(hashCode)从上游bolt(splitBolt)中拉取数据</span></span><br><span class="line">        <span class="comment">// 由于是字段的hashCode，所以相同的单词必定会被传输到同一个wordCountBolt中</span></span><br><span class="line">        <span class="comment">// 每一个spout、bolt都可以emit多个字段，word表示wordCountBolt按照splitBolt的word字段从splitBolt拉取数据</span></span><br><span class="line">        builder.setBolt(<span class="string">"wordCountBolt"</span>,<span class="keyword">new</span> WorldCountBolt(),<span class="number">4</span>).fieldsGrouping(<span class="string">"splitBolt"</span>,<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">        <span class="comment">// storm程序可以在本地启动，也可以打成jar包使用 bin/storm jar xxx.jar mainclass的命令在storm集群上运行</span></span><br><span class="line">        <span class="comment">// 集群模式启动</span></span><br><span class="line">        Config conf = <span class="keyword">new</span> Config();</span><br><span class="line">        <span class="comment">// 设置4个worker数量，一个worker可以认为就是一个jvm。</span></span><br><span class="line">        <span class="comment">// 前一篇文章中，我们部署的storm集群有2个supervisor节点，所以每个supervisor节点上面要启动2个worker进程</span></span><br><span class="line">        conf.setNumWorkers(<span class="number">4</span>);</span><br><span class="line">        StormSubmitter.submitTopologyWithProgressBar(<span class="string">"wordcount"</span>,conf,builder.createTopology());</span><br><span class="line">        <span class="comment">// 本地模式启动</span></span><br><span class="line">        <span class="comment">//conf.setMaxTaskParallelism(3);</span></span><br><span class="line">        <span class="comment">//LocalCluster cluster = new LocalCluster();</span></span><br><span class="line">        <span class="comment">//cluster.submitTopology("word-count", conf, builder.createTopology());</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="spout编写"><a href="#spout编写" class="headerlink" title="spout编写"></a>spout编写</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RandomStringSpout</span> <span class="keyword">extends</span> <span class="title">BaseRichSpout</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> SpoutOutputCollector collector;</span><br><span class="line">    <span class="keyword">private</span> Random rand;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Map map, TopologyContext topologyContext, SpoutOutputCollector spoutOutputCollector)</span> </span>&#123;</span><br><span class="line">        collector = spoutOutputCollector;</span><br><span class="line">        rand = <span class="keyword">new</span> Random();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nextTuple</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        String[] strs = <span class="keyword">new</span> String[]&#123;</span><br><span class="line">          <span class="string">"hello world"</span>,<span class="string">"hello ygq hello tom"</span>,</span><br><span class="line">          <span class="string">"my name is ygq"</span>,<span class="string">"what is your name"</span></span><br><span class="line">        &#125;;</span><br><span class="line">        String str = strs[rand.nextInt(strs.length)];</span><br><span class="line">        <span class="comment">// 将随机的某个字符串发射到下游bolt中</span></span><br><span class="line">        collector.emit(<span class="keyword">new</span> Values(str));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer outputFieldsDeclarer)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 表示这个spout发出的数据字段叫line</span></span><br><span class="line">        outputFieldsDeclarer.declare(<span class="keyword">new</span> Fields(<span class="string">"line"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="bolt编写"><a href="#bolt编写" class="headerlink" title="bolt编写"></a>bolt编写</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SplitBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        collector = outputCollector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 从tuple中取出spout中的line字段的数据，上游spout有可能发出了多个字段，不过本例中spout只发了一个字段line</span></span><br><span class="line">        String line = tuple.getStringByField(<span class="string">"line"</span>);</span><br><span class="line">        String[] words = line.split(<span class="string">" "</span>);</span><br><span class="line">        <span class="keyword">for</span>(String word : words)&#123;</span><br><span class="line">            <span class="comment">// 将切分后的单词发射到下游bolt</span></span><br><span class="line">            collector.emit(<span class="keyword">new</span> Values(word));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer outputFieldsDeclarer)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 表示这个bolt发出的数据字段叫word</span></span><br><span class="line">        outputFieldsDeclarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WorldCountBolt</span> <span class="keyword">extends</span> <span class="title">BaseRichBolt</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> OutputCollector collector;</span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">        这个map用来存每个单词的数量，这里用map来存储其实值得商榷，主要需要考虑几个问题：</span></span><br><span class="line"><span class="comment">            1. 有可能是多个WorldCountBolt线程在同一个worker进程内，那么这个map会不会有线程安全问题？</span></span><br><span class="line"><span class="comment">            其实，由于是根据字段分组fieldsGrouping，所以相同的word必然分配到了相同的WorldCountBolt</span></span><br><span class="line"><span class="comment">            所以在多个线程同时对这个map进行操作时，操作的其实是不同的key，所以是线程安全的</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">            2. 多个WorldCountBolt线程也有可能是运行在多个worker进程中的，甚至可能是运行在多台节点上，</span></span><br><span class="line"><span class="comment">            那么多个WorldCountBolt线程操作的map压根就不在一个进程内，压根就不是同一个map对象，</span></span><br><span class="line"><span class="comment">            所以每个WorldCountBolt线程的map的数据都不完整(但相同单词的个数是正确的)，</span></span><br><span class="line"><span class="comment">            需要将不同进程内的多个map拼接起来才是完整的结果</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">            3. 这里只是为了简单演示才使用了map这种数据结构，一般情况下，可以将计算结果存储到外部介质比如redis</span></span><br><span class="line"><span class="comment">    */</span>   </span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;String, Integer&gt;();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map map, TopologyContext topologyContext, OutputCollector outputCollector)</span> </span>&#123;</span><br><span class="line">        collector = outputCollector;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple)</span> </span>&#123;</span><br><span class="line">        String word = tuple.getStringByField(<span class="string">"word"</span>);</span><br><span class="line">        <span class="keyword">if</span>(map.containsKey(word))&#123;</span><br><span class="line">            Integer count = map.get(word);</span><br><span class="line">            count++;</span><br><span class="line">            map.put(word,count);</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            map.put(word,<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(Thread.currentThread().getName()+<span class="string">" "</span>+map);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer outputFieldsDeclarer)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 由于没有下游bolt了，所以声不声明输出字段都无所谓了</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/13/storm/storm系列一-storm集群安装部署/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/13/storm/storm系列一-storm集群安装部署/" itemprop="url">storm系列一:storm集群安装部署</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-13T00:00:00+08:00">
                2017-10-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>参照storm官网，storm集群部署主要分为一下几步：</p>
<ol>
<li>部署zookeeper集群。storm集群重度依赖zk，用zk来记录很多信息，所以部署storm集群之前要先部署好zk集群</li>
<li>下载安装包并解压到storm集群各节点上</li>
<li>修改各节点的配置文件</li>
<li>使用storm提供的脚本启动storm集群</li>
</ol>
<h1 id="集群安装部署"><a href="#集群安装部署" class="headerlink" title="集群安装部署"></a>集群安装部署</h1><h2 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h2><p>一共使用三台机器，分别是node0、node1、node2，这三台机器上也部署了zk服务端，使用node0作为nimbus，其他两台机器作为supervisor用来启动work。</p>
<p>这里采用的storm安装版本是apache-storm-1.2.1。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar zxf apache-storm-1.2.1.tar.gz -C /usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure>
<p>修改配置文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/apache-storm-1.2.1/conf</span><br><span class="line">vim storm-env.sh </span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.8.0_161/</span><br><span class="line"><span class="comment"># 将原有配置文件备份一份</span></span><br><span class="line">cp storm.yaml&#123;,.bak&#125;</span><br><span class="line">vim storm.yaml </span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置zk集群</span></span><br><span class="line">storm.zookeeper.servers:</span><br><span class="line">     - <span class="string">"node0"</span></span><br><span class="line">     - <span class="string">"node1"</span></span><br><span class="line">     - <span class="string">"node2"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置nimbus节点</span></span><br><span class="line"> nimbus.seeds: [<span class="string">"node0"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Nimbus和Supervisor 用来存放jar和conf等文件的目录</span></span><br><span class="line"> storm.local.dir: <span class="string">"/var/storm_data"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 每一个端口对应一个work进程，代表这个supervisor在本机器上最多启用多少个work，以及占用哪些端口</span></span><br><span class="line"> supervisor.slots.ports:</span><br><span class="line">    - 6700</span><br><span class="line">    - 6701</span><br><span class="line">    - 6702</span><br><span class="line">    - 6703</span><br><span class="line"></span><br><span class="line">scp -r apache-storm-1.2.1/ node1:/usr/<span class="built_in">local</span>/</span><br><span class="line">scp -r apache-storm-1.2.1/ node2:/usr/<span class="built_in">local</span>/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在每一台机器上创建数据目录</span></span><br><span class="line">mkdir -p /var/storm_data</span><br></pre></td></tr></table></figure></p>
<p>要注意storm.yaml配置文件中配置项中的空格，格式必须正确，否则可能启动失败</p>
<h2 id="启动storm集群"><a href="#启动storm集群" class="headerlink" title="启动storm集群"></a>启动storm集群</h2><p>在node0上启动Nimbus<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/storm nimbus &amp;&gt; /dev/null &amp;</span><br></pre></td></tr></table></figure></p>
<p>在node1和node2上启动supervisor<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/storm supervisor  &amp;&gt; /dev/null &amp;</span><br></pre></td></tr></table></figure></p>
<p>在node1上启动storm ui服务，可以在浏览器里查看storm集群的运行情况<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/storm ui  &amp;&gt; /dev/null &amp;</span><br></pre></td></tr></table></figure></p>
<p>然后在浏览器中输入: <a href="http://node1:8080即可查看storm集群的运行状态" target="_blank" rel="noopener">http://node1:8080即可查看storm集群的运行状态</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/11/web架构/hbase集群部署与基本使用/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/11/web架构/hbase集群部署与基本使用/" itemprop="url">hbase集群部署与基本使用</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-11T00:00:00+08:00">
                2017-10-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="hbase安装部署"><a href="#hbase安装部署" class="headerlink" title="hbase安装部署"></a>hbase安装部署</h1><h2 id="解压安装"><a href="#解压安装" class="headerlink" title="解压安装"></a>解压安装</h2><p>这里使用的是1.4.2版本的hbase，可以去官网下载habse安装包，下载后进行解压<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf hbase-1.4.2-bin.tar.gz -C /usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure></p>
<p>为了减少scp时间，可以将一些无用文件删掉<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/hbase-1.4.2</span><br><span class="line">rm -rf docs/ *.txt</span><br></pre></td></tr></table></figure></p>
<p>hbase分为HMaster和HRegionServer，其中HMaster主要管理元数据和HRegionServer的负载均衡等协调工作，而HRegionServer是客户端真正读写数据的地方，对于hbase集群来说，需要配置文件指定哪些是HRegionServer。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim conf/regionservers</span><br><span class="line"><span class="comment"># 将默认的localhost改为如下内容：</span></span><br><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>这里需要说明，一共有3台机器，node0为namenode和hmaster，node1和node2为datanode和regionserver。</p>
</blockquote>
<p>然后需要配置环境变量<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"export  HBASE_HOME=/usr/local/hbase-1.4.2"</span> &gt;&gt; /etc/profile</span><br><span class="line"></span><br><span class="line">vim conf/vim hbase-env.sh</span><br><span class="line"><span class="comment"># 填入自己的JAVA_HOME变量</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.8.0_161/</span><br><span class="line"><span class="comment"># 不使用hbase默认自带的zookeeper，而使用自己集群配置的zk</span></span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGES_ZK=<span class="literal">false</span></span><br></pre></td></tr></table></figure></p>
<p>修改hbase的核心配置文件hbase-site.xml<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">　<span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!-- hbase存放数据目录 --&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!-- 指向hdfs的namenode路径--&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node0:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"> <span class="comment">&lt;!-- 是否分布式部署 --&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="comment">&lt;!-- zk地址 --&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>node0,node1,node2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span> 　　　</span><br><span class="line">　　　<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--zookooper配置、日志等的存储位置 --&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">　　　　　<span class="tag">&lt;<span class="name">value</span>&gt;</span>/var/hbase_zk_data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">　　　<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">　　<span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>分发安装包到其他节点:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r hbase-1.4.2/ node1:/usr/<span class="built_in">local</span>/</span><br><span class="line">scp -r hbase-1.4.2/ node2:/usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure></p>
<p>启动hbase集群，首先要确保hdfs集群和zk集群已启动<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/start-hbase.sh</span><br></pre></td></tr></table></figure></p>
<p>一定要注意的是，几个节点之间的时间一定要同步，否则master会认为一些不同步的regionserver已经挂掉而将其kill了。</p>
<h1 id="java-api操作habse"><a href="#java-api操作habse" class="headerlink" title="java api操作habse"></a>java api操作habse</h1><p>新版的hbase的api有很多变化，之前很多老版本的api已经废弃，这里采用的是hbase1.4.2版本的api，首先导入项目依赖<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.4.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="创建表和删除表"><a href="#创建表和删除表" class="headerlink" title="创建表和删除表"></a>创建表和删除表</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HBaseDemo</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Admin admin;</span><br><span class="line">    <span class="keyword">private</span> Connection conn;</span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Before</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 创建config对象，主要是指定zk地址，因为zk里面记录着regionServer的地址，所以必须要连接zk，客户端才能知道去哪找regionServer</span></span><br><span class="line">        Configuration config = HBaseConfiguration.create();</span><br><span class="line">        config.set(<span class="string">"hbase.zookeeper.quorum"</span>, <span class="string">"node0,node1,node2"</span>);</span><br><span class="line">        config.set(<span class="string">"hbase.zookeeper.property.clientPort"</span>, <span class="string">"2181"</span>);</span><br><span class="line">        <span class="comment">// 通过config对象获取Connection连接对象</span></span><br><span class="line">        <span class="keyword">this</span>.conn = ConnectionFactory.createConnection(config);</span><br><span class="line">        <span class="comment">// 通过Connection对象获取Admin管理类的实例，Admin是一个接口，之前版本的HBaseAdmin实现类已经废弃</span></span><br><span class="line">        <span class="keyword">this</span>.admin = conn.getAdmin();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">CreateTable</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 创建表描述对象，表名为testTable，并向其中添加两个列族，分别是personInfo和companyInfo</span></span><br><span class="line">        HTableDescriptor htd = <span class="keyword">new</span> HTableDescriptor(TableName.valueOf(<span class="string">"testTable"</span>));</span><br><span class="line">        HColumnDescriptor hcd=<span class="keyword">new</span> HColumnDescriptor(<span class="string">"personInfo"</span>);</span><br><span class="line">        htd.addFamily(hcd);</span><br><span class="line">        HColumnDescriptor hcd2=<span class="keyword">new</span> HColumnDescriptor(<span class="string">"companyInfo"</span>);</span><br><span class="line">        htd.addFamily(hcd2);</span><br><span class="line">        <span class="comment">// 创建表</span></span><br><span class="line">        admin.createTable(htd);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">DeleteTable</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 删除表之前必须先disableTable</span></span><br><span class="line">        admin.disableTable(TableName.valueOf(<span class="string">"testTable2"</span>));</span><br><span class="line">        admin.deleteTable(TableName.valueOf(<span class="string">"testTable2"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="添加数据"><a href="#添加数据" class="headerlink" title="添加数据"></a>添加数据</h2><p>这里只列举添加单条数据，插入批量数据和插入单条几乎一样，只不过传入的是一个List<put><br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">AddData</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    Table table = conn.getTable(TableName.valueOf(<span class="string">"testTable"</span>));</span><br><span class="line">    <span class="comment">// 插入单条数据</span></span><br><span class="line">    Put row =<span class="keyword">new</span> Put(Bytes.toBytes(<span class="number">1</span>)); <span class="comment">//设置rowkey</span></span><br><span class="line">    <span class="comment">//向rowkey=1　的personInfo列族添加name=ygq 和 age=27</span></span><br><span class="line">    row.addColumn(Bytes.toBytes(<span class="string">"personInfo"</span>),Bytes.toBytes(<span class="string">"name"</span>),Bytes.toBytes(<span class="string">"ygq"</span>));</span><br><span class="line">    row.addColumn(Bytes.toBytes(<span class="string">"personInfo"</span>),Bytes.toBytes(<span class="string">"age"</span>),Bytes.toBytes(<span class="number">27</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">//向rowkey=1　的companyInfo列族添加name=zondy 和 tel=58767</span></span><br><span class="line">    row.addColumn(Bytes.toBytes(<span class="string">"companyInfo"</span>),Bytes.toBytes(<span class="string">"name"</span>),Bytes.toBytes(<span class="string">"zondy"</span>));</span><br><span class="line">    row.addColumn(Bytes.toBytes(<span class="string">"companyInfo"</span>),Bytes.toBytes(<span class="string">"tel"</span>),Bytes.toBytes(<span class="string">"58767"</span>));</span><br><span class="line">    table.put(row);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></put></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/10/web架构/hdfs的namenode管理元数据机制/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/10/web架构/hdfs的namenode管理元数据机制/" itemprop="url">hdfs的管理元数据机制和RPC框架演示</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-10T00:00:00+08:00">
                2017-10-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="namenode元数据管理"><a href="#namenode元数据管理" class="headerlink" title="namenode元数据管理"></a>namenode元数据管理</h1><p>通过前面几篇博客的讲述，我们知道对于hdfs来说，namenode是至关重要的，客户端不管是上传还是下载文件，都要去namenode中寻找具体的block在哪些datanode上，所以如果namenode的元数据信息丢失，那对于hdfs集群来说是致命的。</p>
<p>既然如此，hdfs是如何管理自己的元数据不丢失的？</p>
<p>假设，用户新上传了一个文件到hdfs，那么namenode中是不是又多了一个元数据。那么这个元数据到底存在哪里？是直接写入磁盘吗？如果是直接写入磁盘，那么如果客户端非常多，大量上传文件时，性能必然很低。就好像mysql插入数据时一样，mysql也不是直接插入磁盘的，而是会先缓存在内存中，然后找一个时机在同步到磁盘里面持久化。</p>
<p>如果namenode将元数据写入内存，新的问题又来了，如果元数据全部保存在内存中的话，虽然性能提高了，但是如果namenode宕机了呢？元数据岂不是全部丢失了，这绝对是灾难。所以namenode必然要每隔一段时间就将元数据信息写入磁盘，以保证数据安全。</p>
<p>所以在前面博客中我们看到了在namenode中有类似于<code>fsimage_0000000000000000028</code>这种文件。这种文件其实就是将namenode元数据信息的内存对象dump(序列号)到磁盘文件。但问题是多久dump一次呢？如果每来一条新的元数据就dump一次肯定不合适，如果间隔太久肯定也不合适，因为假设间隔10分钟同步一次，那么这10分钟之内如果namenode挂了，那这10分钟的数据就丢失了。</p>
<p>由于上述的种种原因，所以hdfs中另一个角色secondary namenode出场了。secondary namenode的主要职责就是管理元数据的镜像文件，他们的工作机制如下图所示：</p>
<p><img src="/images/hadoop/元数据管理.png" alt=""> </p>
<p>每当有新的元数据更新请求时，namenode会先更新管理元数据的内存对象，然后不会写入磁盘，而是写入一个edits日志文件。上篇博客中，我们介绍了namenode的元数据目录结构，如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@ygq hdfsdata] tree</span><br><span class="line">.</span><br><span class="line">└── dfs</span><br><span class="line">    ├── name</span><br><span class="line">    │   ├── current</span><br><span class="line">    │   │   ├── edits_0000000000000000001-0000000000000000002</span><br><span class="line">    │   │   ├── edits_0000000000000000003-0000000000000000015</span><br><span class="line">    │   │   ├── edits_0000000000000000016-0000000000000000022</span><br><span class="line">    │   │   ├── edits_0000000000000000023-0000000000000000024</span><br><span class="line">    │   │   ├── edits_0000000000000000025-0000000000000000026</span><br><span class="line">    │   │   ├── edits_inprogress_0000000000000000027</span><br><span class="line">    │   │   ├── fsimage_0000000000000000024</span><br><span class="line">    │   │   ├── fsimage_0000000000000000024.md5</span><br><span class="line">    │   │   ├── fsimage_0000000000000000026</span><br><span class="line">    │   │   ├── fsimage_0000000000000000026.md5</span><br><span class="line">    │   │   ├── seen_txid</span><br><span class="line">    │   │   └── VERSION</span><br><span class="line">    │   └── in_use.lock</span><br><span class="line">    └── namesecondary</span><br><span class="line">        ├── current</span><br><span class="line">        │   ├── edits_0000000000000000001-0000000000000000002</span><br><span class="line">        │   ├── edits_0000000000000000003-0000000000000000015</span><br><span class="line">        │   ├── edits_0000000000000000016-0000000000000000022</span><br><span class="line">        │   ├── edits_0000000000000000023-0000000000000000024</span><br><span class="line">        │   ├── edits_0000000000000000025-0000000000000000026</span><br><span class="line">        │   ├── fsimage_0000000000000000024</span><br><span class="line">        │   ├── fsimage_0000000000000000024.md5</span><br><span class="line">        │   ├── fsimage_0000000000000000026</span><br><span class="line">        │   ├── fsimage_0000000000000000026.md5</span><br><span class="line">        │   └── VERSION</span><br><span class="line">        └── in_use.lock</span><br></pre></td></tr></table></figure></p>
<p>可以看到有一个个的edits文件。其中namesecondary就是secondary namenode。这里需要说明的是，一般情况下这两个目录不会在同一台服务器，这里只是由于实验环境为了节省机器，所以将secondary namenode和主namenode配置在同一台机器，正常情况下两者是分开的(HA集群下情况另算)。</p>
<p>通过上述结构，我们可以看出，edits日志文件也是可以滚动的，edits_inprogress代表正在写入的。</p>
<p>edits文件中记录的是什么呢？其实里面记录的是元数据的更新操作，是追加性写入(非常类似与mysql中的redo log)。那么如果有了edits文件，前面所提到的问题就解决了，比如假设上一次同步磁盘之后的某段时间namenode宕机，那再次启动namenode时就不会丢失数据，因为可以使用最新的fsimage+edits文件得到宕机前的所有数据。</p>
<p>但是这样有引入了新的问题，通过上面结构我们也看到了edits文件随着日积月累会越来越多，那么当namenode宕机再次启动时，岂不是要恢复很久？所以为了解决这个问题，就需要定期的将edits文件和fsimage文件合并，这样的话，namenode再次启动时，edits文件只有很小一部分需要合并，速度就会快很多。这个合并工作肯定不能归namenode自己去做，所以是有secondary namenode来进行合并的，基于此就引入了checkpoint机制。</p>
<h2 id="checkpoint机制"><a href="#checkpoint机制" class="headerlink" title="checkpoint机制"></a>checkpoint机制</h2><p>checkpoint触发是需要条件的，这些用户可以配置：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 检查触发条件是否满足的频率，60秒 --&gt;</span></span><br><span class="line">dfs.namenode.checkpoint.check.period=60  </span><br><span class="line">dfs.namenode.checkpoint.dir=file://$&#123;hadoop.tmp.dir&#125;/dfs/namesecondary</span><br><span class="line"><span class="comment">&lt;!-- 以上两个参数做checkpoint操作时，secondary namenode的本地工作目录 --&gt;</span></span><br><span class="line">dfs.namenode.checkpoint.edits.dir=$&#123;dfs.namenode.checkpoint.dir&#125;</span><br><span class="line"><span class="comment">&lt;!-- 最大重试次数 --&gt;</span></span><br><span class="line">dfs.namenode.checkpoint.max-retries=3  </span><br><span class="line"><span class="comment">&lt;!-- 两次checkpoint之间的时间间隔3600秒 --&gt;</span></span><br><span class="line">dfs.namenode.checkpoint.period=3600  </span><br><span class="line"><span class="comment">&lt;!-- 两次checkpoint之间最大的操作记录 --&gt;</span></span><br><span class="line">dfs.namenode.checkpoint.txns=1000000</span><br></pre></td></tr></table></figure></p>
<p>具体的流程如下：</p>
<ol>
<li>secondary namenode向namenode请求，询问是否需要进行checkpoint</li>
<li>namenode检查是否满足checkpoint条件，假设满足</li>
<li>secondary namenode发起checkpoint的请求</li>
<li>namenode立即滚动一次正在写的edit文件(edits_inprogress)</li>
<li>secondary namenode将namenode上的edit文件和fsimage文件下载到本地，并加载到内存进行合并，然后在dump成一个新的fsimage文件</li>
<li>secondary namenode将新的fsimage文件上传到namenode，覆盖原有fsimage文件</li>
</ol>
<h1 id="hadoop内部rpc框架使用"><a href="#hadoop内部rpc框架使用" class="headerlink" title="hadoop内部rpc框架使用"></a>hadoop内部rpc框架使用</h1><p>hadoop内部各节点之间通信都是通过rpc进行的，这里使用hadoop内部提供的rpc框架编写一个客户端调用服务端方法的例子。</p>
<p>首先服务端需要将待发布的服务封装成一个接口，我们来自定义这个接口:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">ClientNamenodeProtocol</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 这个versionID字段必须要有，而且名字必须是versionID</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> versionID = <span class="number">0L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getMetaData</span><span class="params">(String path)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>然后服务端需要写一个接口的实现类，并将其发布成服务，这里为了简便直接将服务端写成了实现类:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">PublishService</span> <span class="keyword">implements</span> <span class="title">ClientNamenodeProtocol</span></span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 创建一个Builder，用来设置服务端信息</span></span><br><span class="line">        RPC.Builder builder = <span class="keyword">new</span> RPC.Builder(<span class="keyword">new</span> Configuration());</span><br><span class="line">        builder.setBindAddress(<span class="string">"127.0.0.1"</span>).setPort(<span class="number">1314</span>)   <span class="comment">// 绑定服务端ip和端口</span></span><br><span class="line">                .setProtocol(ClientNamenodeProtocol.class)  <span class="comment">// 设置服务端的协议，也就是服务接口</span></span><br><span class="line">                .setInstance(<span class="keyword">new</span> PublishService());         <span class="comment">// 设置实现类的实例</span></span><br><span class="line">        RPC.Server server = builder.build();</span><br><span class="line">        <span class="comment">// 启动服务端并发布服务</span></span><br><span class="line">        server.start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 服务端实现接口</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getMetaData</span><span class="params">(String path)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> path+<span class="string">"[blk_01,blk_02,blk_03] &#123;blk_01:node01,node02&#125;"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>至此，服务端就简单的将一个getMetaData的方法发布为服务，供其他节点去调用，剩下的就是客户端调用了:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// 获取代理对象</span></span><br><span class="line">        ClientNamenodeProtocol proxy = RPC.getProxy(</span><br><span class="line">            ClientNamenodeProtocol.class,   <span class="comment">// 设置服务端的协议，也就是服务接口</span></span><br><span class="line">            <span class="number">0L</span>,                             <span class="comment">// 服务端协议的versionID</span></span><br><span class="line">            <span class="keyword">new</span> InetSocketAddress(<span class="string">"127.0.0.1"</span>, <span class="number">1314</span>), <span class="comment">// 服务端的ip和端口</span></span><br><span class="line">            <span class="keyword">new</span> Configuration());</span><br><span class="line">        <span class="comment">// 得到代理对象后，调用服务接口的方法，请求服务端</span></span><br><span class="line">        String metaData = proxy.getMetaData(<span class="string">"/input"</span>);</span><br><span class="line">        System.out.println(metaData);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/09/web架构/HDFS读写流程详解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/09/web架构/HDFS读写流程详解/" itemprop="url">HDFS读写流程源码探究</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-09T00:00:00+08:00">
                2017-10-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>上一篇博客中我们大致讲述了hdfs中几个比较重要的角色，namenode、datanode。这篇文章会将hdfs上传和下载文件的过程细化。</p>
<p>在写上传和下载文件之前，先想一个问题，我们知道hdfs的datanode是可以随时动态扩容的，那么datanode是怎么知道自己是属于哪个namonode的？</p>
<p>首先，我们在每一个节点(包括namenode和datanode)的配置文件中都设置了namenode的地址。</p>
<p>而且在namenode第一次启动之前，我们会执行<code>hdfs namenode -format</code>对namenode的数据目录进行格式化，这个格式化其实就是生成一些标识文件和目录。</p>
<p>假设我们配置的namenode的数据目录为/var/hdfsdata，那么在这个路径下的目录如下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[root@ygq hdfsdata] tree</span><br><span class="line">.</span><br><span class="line">└── dfs</span><br><span class="line">    ├── name</span><br><span class="line">    │   ├── current</span><br><span class="line">    │   │   ├── edits_0000000000000000001-0000000000000000002</span><br><span class="line">    │   │   ├── edits_0000000000000000003-0000000000000000015</span><br><span class="line">    │   │   ├── edits_0000000000000000016-0000000000000000022</span><br><span class="line">    │   │   ├── edits_0000000000000000023-0000000000000000024</span><br><span class="line">    │   │   ├── edits_0000000000000000025-0000000000000000026</span><br><span class="line">    │   │   ├── edits_inprogress_0000000000000000027</span><br><span class="line">    │   │   ├── fsimage_0000000000000000024</span><br><span class="line">    │   │   ├── fsimage_0000000000000000024.md5</span><br><span class="line">    │   │   ├── fsimage_0000000000000000026</span><br><span class="line">    │   │   ├── fsimage_0000000000000000026.md5</span><br><span class="line">    │   │   ├── seen_txid</span><br><span class="line">    │   │   └── VERSION</span><br><span class="line">    │   └── in_use.lock</span><br><span class="line">    └── namesecondary</span><br><span class="line">        ├── current</span><br><span class="line">        │   ├── edits_0000000000000000001-0000000000000000002</span><br><span class="line">        │   ├── edits_0000000000000000003-0000000000000000015</span><br><span class="line">        │   ├── edits_0000000000000000016-0000000000000000022</span><br><span class="line">        │   ├── edits_0000000000000000023-0000000000000000024</span><br><span class="line">        │   ├── edits_0000000000000000025-0000000000000000026</span><br><span class="line">        │   ├── fsimage_0000000000000000024</span><br><span class="line">        │   ├── fsimage_0000000000000000024.md5</span><br><span class="line">        │   ├── fsimage_0000000000000000026</span><br><span class="line">        │   ├── fsimage_0000000000000000026.md5</span><br><span class="line">        │   └── VERSION</span><br><span class="line">        └── in_use.lock</span><br></pre></td></tr></table></figure></p>
<p>我们先不管namesecondary和其他的edits、fsimage文件，在name目录下，有一个VERSION文件，这里面就存放了以当前namenode为首的hdfs集群的基本信息，如集群id等。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cat VERSION</span><br><span class="line"></span><br><span class="line">namespaceID=1411893727</span><br><span class="line">clusterID=CID-703e558a-a96c-4e87-9a78-dd8314244fb0</span><br><span class="line">cTime=0</span><br><span class="line">storageType=NAME_NODE</span><br><span class="line">blockpoolID=BP-480178269-192.167.0.74-1515698717067</span><br><span class="line">layoutVersion=-60</span><br></pre></td></tr></table></figure></p>
<p>可以看到有namespaceID，这个主要是实现HA机制的，先不管。然后就是clusterID=CID-703e558a-a96c-4e87-9a78-dd8314244fb0，这个ID就是标识了当前集群，所有将namenode地址配置为本机器的datanode将会自动与此namenode建立联系。</p>
<p>我们再看datanode的数据目录，<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可以看到datanode数据目录结构和namenode不同，这里不是name和namesecondary，而是data</span></span><br><span class="line"><span class="built_in">cd</span> /var/hdfsdata/dfs/data/current/</span><br><span class="line">cat VERSION</span><br><span class="line"></span><br><span class="line">storageID=DS-c5676a44-1cf7-481d-b748-dbcca2c0ebc5</span><br><span class="line">clusterID=CID-703e558a-a96c-4e87-9a78-dd8314244fb0</span><br><span class="line">cTime=0</span><br><span class="line">datanodeUuid=d6b0d976-0bd0-435f-af57-99df676dc79a</span><br><span class="line">storageType=DATA_NODE</span><br></pre></td></tr></table></figure></p>
<p>可以看到datanode的storageType=DATA_NODE，并且clusterID对应的就是namenode中的clusterID。</p>
<p>所以如果将namenode再执行一次格式化，那么namenode中clusterID和datanode必然不一致了，此时datanode就必然找不到namenode，集群也就没法正常工作了。</p>
<h2 id="HDFS上传文件"><a href="#HDFS上传文件" class="headerlink" title="HDFS上传文件"></a>HDFS上传文件</h2><p>HDFS的上传文件流程比较复杂，我也只能理解一些大体流程，不过我觉得理解大体工作流程对于开发来说是非常有必要的，如果需要再深层次的理解，就需要一行行的调试源码了。具体的文件上传流程如下图所示：<br><img src="/images/hadoop/上传文件.png" alt=""> </p>
<p>当客户端发起上传文件a.txt的请求时(shell客户端或者使用java api上传文件)，大致分为如下几步：</p>
<ol>
<li>通过rpc请求到namenode,请求上传a.txt文件到某目录。然后namenode自身检查文件是否已经存在以及权限认证等，然后返回给客户端是否可上传</li>
<li>假设a.txt比较大，有300M，假设设置的每个block为128M，客户端就会将文件切成3个block。(这里要注意是在客户端切片。)然后客户端再次向namenode发请求，请求上传第一个block。</li>
<li>由于hdfs支持副本机制，所以每一个block可能会存在多个datanode上(但不会同一个datanode上存多个相同的block，因为这样没意义)，具体副本数量由客户端决定，如果客户端没有设置副本数量，则采用服务端默认的副本数量。假设副本数量为3，那么namenode就要返回3个datanode地址给客户端，假设为dn1、dn2、dn3</li>
<li>namenode具体选取哪几个namenode存放这些block，一般要考虑这些datanode的容量，以及网络拓扑(比如优先本地)等</li>
<li><p>客户端拿到datanode地址后，就会与其中一个datanode建立通信连接，然后向此datanode发送数据。<br> 这个发送数据的过程比较复杂，下面一步步来讲，首先我们知道，客户端不止要向1个datanode发送数据，但事实上是这样的吗？事实上，客户端只向一个datanode发送数据，这个datanode(假设为dn1)会自己向dn2建立channel，然后dn2向dn3建立channel(只是一种假设，具体谁和谁建立channel不确定，但可以确定的是从客户端-&gt;多个datanode之间是通过channel流式传输数据的，而客户端确实只传输给1个datanode，这个datanode再传给另外一个datanode，依次建立连接传输数据)</p>
<p> 另外，客户端具体是怎么给dn1发送数据的?上篇博客中我们知道hdfs客户端api分为流式上传和整体上传(比如fs.copyFromLocalFile)，但追踪源码我们知道，哪怕是fs.copyFromLocalFile，其内部也是采用流式传输。通过调试断点得知，具体实现的源码如下。buffSize是什么？从下面的实现中可以看到，客户端一次传输buffSize字节长度数据到datanode，直到传输完毕也就是bytesRead = in.read(buf)=-1.<br> 那么buffSize是多大呢？也就是上图中客户端一个packet的大小是多大？其实这个是配置文件、或者我们java api中客户端设定的io.file.buffer.size来决定的。通过源码我们可以看到具体为<code>conf.getInt(&quot;io.file.buffer.size&quot;, 4096)</code>，也就是默认4K。</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//hdfs客户端实现上传文件的核心方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">copyBytes</span><span class="params">(InputStream in, OutputStream out, <span class="keyword">int</span> buffSize)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    PrintStream ps = out <span class="keyword">instanceof</span> PrintStream ? (PrintStream)out : <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[buffSize];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> bytesRead = in.read(buf); bytesRead &gt;= <span class="number">0</span>; bytesRead = in.read(buf)) &#123;</span><br><span class="line">        out.write(buf, <span class="number">0</span>, bytesRead);</span><br><span class="line">        <span class="keyword">if</span> (ps != <span class="keyword">null</span> &amp;&amp; ps.checkError()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unable to write to output stream."</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>当客户端将第一个block的一个个的packet发送完之后，会按照同样的方式再次发送第二个block，直到发送完所有数据。</p>
</li>
</ol>
<h2 id="HDFS读数据流程"><a href="#HDFS读数据流程" class="headerlink" title="HDFS读数据流程"></a>HDFS读数据流程</h2><p>HDSF读取文件流程比上传文件稍微简单些。具体的核心实现方法和上传一样，都是<code>public static void copyBytes(InputStream in, OutputStream out, int buffSize)</code>分成多个packet流式上传。具体的步骤如下图所示：</p>
<p><img src="/images/hadoop/读文件.png" alt=""> </p>
<p>当客户端发起下载文件a.txt的请求时(shell客户端或者使用java api下载文件)，大致分为如下几步：</p>
<ol>
<li><p>通过rpc请求到namenode，请求下载a.txt文件，然后namenode自身检查文件是否存在以及权限等，如果存在，则返回给客户端这些文件的block在哪些datanode上。假设返回的数据为:</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;BLK_1,BLK_2,BLK3&#125; </span><br><span class="line">&#123;BLK1:DN1,DN2,DN3 BLK_2:DN1,DN3,DN4 ...&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>根据namenode的返回结果，客户端就知道了要下载的文件有多少block，并且这些block各在哪些datanode上，假设在dn1、dn3上</p>
</li>
<li>客户端向dn1发起请求，请求下载BLK_1,具体的下载过程和上小节中上传文件是完全一样的，也是使用copyBytes流式获取数据。</li>
<li>当客户端BLK_1下载完成后，再向dn3请求下一个block，依次请求完全部的block之后，在客户端直接拼接(多个block直接追加合并即可，因为之前客户端切分就是直接按字节切分的)成完整文件。</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/08/web架构/HDFS集群安装与配置、原理详解/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/08/web架构/HDFS集群安装与配置、原理详解/" itemprop="url">HDFS集群安装与配置、原理详解</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-08T00:00:00+08:00">
                2017-10-08
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="HDFS集群安装与配置"><a href="#HDFS集群安装与配置" class="headerlink" title="HDFS集群安装与配置"></a>HDFS集群安装与配置</h1><p>标题之所以没有叫hadoop是因为本文只将HDFS的部署和运行机制。从Hadoop2.x版本以后，Hadoop的核心组件分为HDFS、MapReduce、Yarn。</p>
<p>其中，HDFS只负责分布式文件存储；MapReduce只负责具体job的分布式离线计算，比如统计对存储在HDFS上的文件中的数据进行统计、排序等等操作；Yarn负责对这些job进行调度。</p>
<p>安装hadoop时，会将这三个组件全部安装，并且提供了各自的配置文件。不过我们可以选择性的只启动某个组件。</p>
<p>这里之所以只写HDFS，也是因为个人觉得HDFS更重要一些。不管是什么样的架构和系统，必然少不了一个分布式文件存储系统，当然HDFS也不是唯一选择，由于HDFS自身的一些特性，很多场景并不适合使用HDFS，这个我们后面再谈。不管是mapreduce、storm还是spark，都可以基于hdfs进行相关处理。而mapreduce和yarn则未必。</p>
<p>下面就参考hadoop官网给出的文档来写下如何安装与配置一个hdfs的集群，本篇文章只讲单namenode模式，联邦机制下的hdfs如果有时间的话就单独再写一篇文章来具体讲。从配置和运行机制上来说，联邦机制下的hdfs都要麻烦不少，而且所需的机器更多，实验环境下不太好部署，少说也得5 6台机器。而且对于开发人员来说，只要配置文件写好，底层hdfs不管是不是运行在联邦机制下，程序代码都是一样的，这些相对来说更偏重运维一些。</p>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>这里采用三台虚拟机进行实验部署，分别为node0、node1、node2。其中，node0作为namenode和second namenode，其余2台作为datanode。至于什么是namenode和datanode，以及hdfs集群的运作方式，后面会很详细的讲清楚，这里先让集群跑起来再说把！</p>
<p>当然，由于要部署集群，所以各节点之间时间最好要同步；另外，各节点之间最好配置了ssh免密登录。如果要使用hadoop提供的脚本来启动集群的话，就必须配置免密登录。</p>
<p>另外，hadoop是java写的，必然也需要安装jdk环境。</p>
<p>然后是下载安装包，这里以hadoop-2.6.5.tar.gz为例，可以到官网去下载压缩包。这里说的压缩包是以及打包编译好的，而不是源码包。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar xf hadoop-2.6.5.tar.gz -C /usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure>
<p>解压完成后，需要配置一些环境变量和启动参数，这里就参照官网的配置一切从简，大多数参数采用默认即可。这里只说几个必须要配置的参数。</p>
<p>首先，配置HADOOP_HOME环境变量。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"export HADOOP_HOME=/usr/local/hadoop-2.6.5/"</span> &gt;&gt; /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将配置文件copy到其他两个节点</span></span><br><span class="line"></span><br><span class="line">scp /etc/profile node1:/etc</span><br><span class="line">scp /etc/profile node2:/etc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在三个节点上均重读配置文件</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></p>
<p>然后，修改hadoop-env.sh文件中的一些参数，这里面可以指定JAVA_HOME，以及指定hadoop运行时的一些参数，比如采用哪种gc，占用多少内存等等的。由于后面我们要使用hadoop提供的脚本来启动hdfs，所以其余节点是通过ssh命令来被执行启动datanode，所以在子shell中会读取不到JAVA_HOME环境变量，必须我们自己指定<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim hadoop-env.sh</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/jdk1.8.0_161/</span><br></pre></td></tr></table></figure></p>
<p>然后，我们需要修改core-site.xml文件来告诉hdfs集群，哪个是namenode，这样当hdfs节点启动时，就会自己去找配置文件中指定的namenode，自动加入集群。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;!--指定namenode的地址--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://node0:9000&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;!--用来指定使用hadoop时产生文件的存放目录--&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;/var/hdfsdata&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line"> &lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p>
<p>当然还有很多很重要的参数，比如io.file.buffer.size来决定文件读写的buffer大小，dfs.blocksize决定文件切片的大小，dfs.namenode.name.dir决定namenode的元数据存放目录等，这里由于只是实验演示，所以就直接采用默认了，生产环境下肯定要根据自身服务器配置进行不同的配置调整。</p>
<p>最后，还有一个文件需要配置，就是slaves，这个文件其实和hadoop自身没什么关系，不配置也能运行，只不过如果想使用hadoop提供的start-dfs.sh脚本时，就会去读取这个文件中写入的主机，并挨个使用ssh命令启动他们，所以我们这里要配置下。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim slaves</span><br><span class="line"></span><br><span class="line">node1</span><br><span class="line">node2</span><br></pre></td></tr></table></figure>
<p>最后，所有配置完成，我们使用scp将这些文件统统拷贝到另外两个节点<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r hadoop-2.6.5/ node1:/usr/<span class="built_in">local</span>/</span><br><span class="line"></span><br><span class="line">scp -r hadoop-2.6.5/ node2:/usr/<span class="built_in">local</span>/</span><br></pre></td></tr></table></figure></p>
<p>然后，启动hdfs<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在node0上，也就是我们的namenode上，进行格式化</span></span><br><span class="line"><span class="variable">$HADOOP_HOME</span>/bin/hdfs namenode -format</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用脚本启动所有节点</span></span><br><span class="line"><span class="variable">$HADOOP_HOME</span>/sbin/start-dfs.sh</span><br></pre></td></tr></table></figure></p>
<p>此时，顺利的话，hdfs的3个节点的集群就启动成功了。<br>在node0上使用jps可以看到:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">9088 SecondaryNameNode</span><br><span class="line">9193 Jps</span><br><span class="line">8924 NameNode</span><br></pre></td></tr></table></figure></p>
<p>在node1和node2上可以看到：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">4882 Jps</span><br><span class="line">4814 DataNode</span><br></pre></td></tr></table></figure></p>
<p>在浏览器里输入<a href="http://node0:50070可以进入一个hadoop提供的web页面，可以查看到当前hdfs集群的运行状况。" target="_blank" rel="noopener">http://node0:50070可以进入一个hadoop提供的web页面，可以查看到当前hdfs集群的运行状况。</a></p>
<h1 id="hdfs的总体概要"><a href="#hdfs的总体概要" class="headerlink" title="hdfs的总体概要"></a>hdfs的总体概要</h1><p>上一节中主要写了hadoop的安装与部署(hdfs模块)，只是初步将集群部署及运行起来，并没有过多的讲述关于hdfs内部运行的一些细节。这一节中，主要讲一些hdfs中的核心名词和概念，也不会太深入涉及hdfs细节，限于文章篇幅，具体的hdfs工作原理放在下一篇博客中写。</p>
<h2 id="hdfs是什么"><a href="#hdfs是什么" class="headerlink" title="hdfs是什么"></a>hdfs是什么</h2><p>首先，hdfs是一个文件系统，是用来存放文件的；其次，hdfs是分布式的，可以用很多台机器来存放和管理用户上传的文件。</p>
<p>既然hdfs是将用户上传的文件保存在多台机器上，那么是不是得有一种机制来记忆到底哪些文件存放在哪些机器上？</p>
<p>另外一个问题，如果用户上传的文件特别大，比如一个用户访问日志、或者一个地图数据文件，动不动上G甚至更大都有可能，如果将这么大的一个文件从客户端上传到HDFS服务器集群，是不是会特别慢!?</p>
<p>而且我们知道，HDFS只是用来做文件存储，供其他系统进行调用的。比如当我们使用mapreduce或者spark程序读取并处理一个特别大的文件，如果这个文件整个的存放在某一台机器上时，是不是就无法充分利用我们的mapreduce和spark分布式的优势了？</p>
<p>基于上述的一些问题，所以才有了hdfs实际的工作原理。</p>
<p>在hdfs中，有两个非常重要的概念，前面我们在部署hdfs的时候也用到了，就是namenode和datanode。</p>
<p>其中datanode只用来存放具体的文件，而namenode负责保存了所有用户上传的文件的元数据信息。比如哪些文件在哪些datanode上面。</p>
<p>而为了解决单个文件过大的问题，hdfs会将用户上传的文件进行切片。将一个大文件切成多个block，分别存放在不同的datanode上，并且会在namenode上记录哪些block存放在哪些datanode上。</p>
<h2 id="使用java-api操作hdfs"><a href="#使用java-api操作hdfs" class="headerlink" title="使用java api操作hdfs"></a>使用java api操作hdfs</h2><p>java api操作hdfs比较简单，基本上和hdfs提供的shell客户端差不多。不过在操作大文件的时候，我们可能要使用流式读取的方式。流式读取的方式也有很多种，可以使用最普通的FileInputStream，也可以使用nio的FileChannel。但不管使用哪种方式，一定要控制好读取的长度和偏移量，防止重读或者漏读数据。</p>
<p>由于安装的hadoop版本是2.6.5版本的，所以使用的是2.6.5版本的hadoop-client，在项目的pom.xml文件中添加如下依赖即可。<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HDFSDemo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">            获得FileSystem的实例，这里需要注意，FileSystem是一个抽象类，他有多个实现类</span></span><br><span class="line"><span class="comment">            可以通过指定不同的URI类型来创建不同的FileSystem实现类</span></span><br><span class="line"><span class="comment">            如果不指定URI直接创建，会创建LocalFileSystem本地文件系统操作类，也即file://格式的路径</span></span><br><span class="line"><span class="comment">            这里选择DistributedFileSystem实现类，URI指向我们的namenode的地址和端口</span></span><br><span class="line"><span class="comment">            第三个参数是指定使用哪个用户进行上传，默认会使用当前系统用户。如果用户名和hdfs上目标路径的属主不一致，会抛拒绝访问异常</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line"></span><br><span class="line">        FileSystem fs = FileSystem.get(<span class="keyword">new</span> URI(<span class="string">"hdfs://node0:9000"</span>), <span class="keyword">new</span> Configuration(), <span class="string">"root"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将本地目录下某文件上传到hdfs指定目录</span></span><br><span class="line">        fs.copyFromLocalFile(<span class="keyword">new</span> Path(<span class="string">"/home/ygq/out"</span>), <span class="keyword">new</span> Path(<span class="string">"/"</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">            上述方式是整个将文件上传到hdfs或整个从hdfs下载到本地客户端</span></span><br><span class="line"><span class="comment">            但是如果文件太大，或者想指定文件偏移量，这种方式就不合适了，可以使用流的方式分片上传或下载</span></span><br><span class="line"><span class="comment">            fs.open() 会流式读取hdfs上指定路径的一个文件，并读取一定长度的字节</span></span><br><span class="line"><span class="comment">            每次读多少长度可以自己指定，查看源码可知默认读取io.file.buffer.size设定的长度,可以看到默认读取4096字节</span></span><br><span class="line"><span class="comment">            this.open(f, this.getConf().getInt("io.file.buffer.size", 4096));</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        FSDataInputStream in = fs.open(<span class="keyword">new</span> Path(<span class="string">"/out"</span>));</span><br><span class="line">        <span class="comment">// 获取文件的元数据信息，比如有多少block，文件大小等等</span></span><br><span class="line">        FileStatus fileStatus = fs.getFileStatus(<span class="keyword">new</span> Path(<span class="string">"/out"</span>));</span><br><span class="line">        <span class="comment">// 获取文件大小，单位是字节</span></span><br><span class="line">        <span class="keyword">long</span> fileLen = fileStatus.getLen();</span><br><span class="line">        <span class="comment">// 记录每次读取到的字节数</span></span><br><span class="line">        <span class="keyword">int</span> len = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 记录总共读取到的字节数</span></span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">// 使用nio的ByteBuffer来流式读取，当然也可以不用nio方式读取，这个都可以</span></span><br><span class="line">        <span class="comment">// 只不过不管用哪种方式读取，都需要控制好读取的长度和偏移量，防止重读或者漏读数据</span></span><br><span class="line">        <span class="comment">// 这里只是将读取到的数据打印到控制台，当然也可以写入本地文件</span></span><br><span class="line">        ByteBuffer byteBuf = ByteBuffer.allocate(<span class="number">4096</span>);</span><br><span class="line">        <span class="keyword">while</span> ((len = in.read(byteBuf)) != -<span class="number">1</span>) &#123;</span><br><span class="line">            sum += len;</span><br><span class="line">            byteBuf.flip();</span><br><span class="line">            <span class="keyword">byte</span>[] buf = <span class="keyword">new</span> <span class="keyword">byte</span>[byteBuf.remaining()];</span><br><span class="line">            byteBuf.get(buf);</span><br><span class="line">            System.out.print(<span class="keyword">new</span> String(buf, <span class="string">"UTF-8"</span>));</span><br><span class="line">            byteBuf.clear();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"源文件大小:"</span> + fileLen + <span class="string">"字节,一共读取到:"</span> + sum + <span class="string">"字节"</span>);</span><br><span class="line">        in.close();</span><br><span class="line">        fs.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/07/java/基于生产者-消费者模型的多线程探究/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ygqqq">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="for the dream">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/07/java/基于生产者-消费者模型的多线程探究/" itemprop="url">基于生产者-消费者模型的多线程探究</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-07T00:00:00+08:00">
                2017-10-07
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/java/" itemprop="url" rel="index">
                    <span itemprop="name">java</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>多线程在java应用开发中的重要性不必多说，但多线程开发比起单线程模型，多了很多特别需要注意的事项！</p>
<p>多线程最容易出错的地方无疑是线程安全问题以及死锁问题。线程安全还好，可以通过同步代码块或者采用concurrent包中的locks来自行加锁解锁进行线程安全控制，但还有死锁的问题必须要防范。</p>
<p>而且并非在同步代码块中的对象就一定是线程安全的，具体情况还要看采用的锁对象和要操作的对象。</p>
<p>多线程开发中有特别多的细节要考虑，比如sleep和wait的区别、线程等待池和锁池的区别、同步方法和同步代码块的区别、volatile和synchronized关键字的区别、notify和notifyAll的区别、进程上下文切换和线程上下文切换的区别、用户线程和内核线程的区别以及用户态和内核态之间的转换等等…</p>
<p>有些是java语言层面的，有些是操作系统层面的，但这些都会影响到我们写出来的程序的执行正确性和是否高效，所以作为一名开发人员，真的有必要探究清楚这其中的一些细节和差异。</p>
<h1 id="单生产者-单消费者模型"><a href="#单生产者-单消费者模型" class="headerlink" title="单生产者-单消费者模型"></a>单生产者-单消费者模型</h1><p>代码如下，这里先从最基础的 单生产者-单消费者 而且产品也只有1个的讲起。为了方便，产品和生产者、消费者都写成了内部类。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 单一产品、非队列模式的生产者-消费者模型</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NoneQueue</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Product product;</span><br><span class="line">    <span class="comment">//产品类</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String name;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Product</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.name = name;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> name;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//生产者</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> num = <span class="number">1</span>;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">100</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">synchronized</span> (NoneQueue.<span class="keyword">this</span>) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (product == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        String name = Thread.currentThread().getName() + <span class="string">"的第"</span> + num + <span class="string">"个产品"</span>;</span><br><span class="line">                        product = <span class="keyword">new</span> Product(name);</span><br><span class="line">                        System.out.println(Thread.currentThread().getName() + <span class="string">"生产了 -&gt; "</span> + name);</span><br><span class="line">                        num++;</span><br><span class="line">                        NoneQueue.<span class="keyword">this</span>.notify();</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="keyword">try</span> &#123;</span><br><span class="line">                            NoneQueue.<span class="keyword">this</span>.wait();</span><br><span class="line">                        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//消费者</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">100</span>);</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">synchronized</span> (NoneQueue.<span class="keyword">this</span>) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (product != <span class="keyword">null</span>) &#123;</span><br><span class="line">                        System.out.println(Thread.currentThread().getName() + <span class="string">"消费了 -&gt; "</span> + product.getName());</span><br><span class="line">                        product = <span class="keyword">null</span>;</span><br><span class="line">                        NoneQueue.<span class="keyword">this</span>.notify();</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        <span class="keyword">try</span> &#123;</span><br><span class="line">                            NoneQueue.<span class="keyword">this</span>.wait();</span><br><span class="line">                        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                            e.printStackTrace();</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        NoneQueue noneQueue = <span class="keyword">new</span> NoneQueue();</span><br><span class="line">        <span class="keyword">new</span> Thread(noneQueue.new Producer()).start();</span><br><span class="line">        <span class="keyword">new</span> Thread(noneQueue.new Consumer()).start();</span><br><span class="line">        Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>synchronized (NoneQueue.this)</code>表示采用当前NoneQueue的实例对象作为锁对象，由于当前demo只有一个NoneQueue实例，所以锁对象也是唯一的。</p>
<p>这个程序大体流程很简单，就是main方法中启动了两个线程，一个生产者，一个消费者。生成者判断产品是否为null，如果为null则生产，生产完之后调用<code>NoneQueue.this.notify()</code>来唤醒等待池中的线程。由于当前情况只有生成者和消费者2个线程，那么被唤醒的只可能是消费者。如果生产者发现产品不为null，说明消费者还未消费，生产者就调用<code>NoneQueue.this.wait();</code>释放锁对象，将自己加入等待池，等待消费者消费并将自己唤醒。</p>
<p>这种情况是不会出问题的，程序运行结果如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Thread-<span class="number">0</span>生产了 -&gt; Thread-<span class="number">0</span>的第<span class="number">1</span>个产品</span><br><span class="line">Thread-<span class="number">1</span>消费了 -&gt; Thread-<span class="number">0</span>的第<span class="number">1</span>个产品</span><br><span class="line">Thread-<span class="number">0</span>生产了 -&gt; Thread-<span class="number">0</span>的第<span class="number">2</span>个产品</span><br><span class="line">Thread-<span class="number">1</span>消费了 -&gt; Thread-<span class="number">0</span>的第<span class="number">2</span>个产品</span><br><span class="line">Thread-<span class="number">0</span>生产了 -&gt; Thread-<span class="number">0</span>的第<span class="number">3</span>个产品</span><br><span class="line">Thread-<span class="number">1</span>消费了 -&gt; Thread-<span class="number">0</span>的第<span class="number">3</span>个产品</span><br><span class="line">Thread-<span class="number">0</span>生产了 -&gt; Thread-<span class="number">0</span>的第<span class="number">4</span>个产品</span><br><span class="line">Thread-<span class="number">1</span>消费了 -&gt; Thread-<span class="number">0</span>的第<span class="number">4</span>个产品</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h1 id="多个生产者和多个消费者模型"><a href="#多个生产者和多个消费者模型" class="headerlink" title="多个生产者和多个消费者模型"></a>多个生产者和多个消费者模型</h1><p>但是如果将main方法改下，就是说不只有一个生产者和一个消费者，那么上面的代码就会出现问题。比如main方法改成如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public static void main(String args[]) throws InterruptedException &#123;</span><br><span class="line">    NoneQueue noneQueue = new NoneQueue();</span><br><span class="line">    for (int i = 0; i &lt; 4; i++) &#123;</span><br><span class="line">        new Thread(noneQueue.new Producer()).start();</span><br><span class="line">        new Thread(noneQueue.new Consumer()).start();</span><br><span class="line">    &#125;</span><br><span class="line">    Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>此时程序运行结果:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Thread-<span class="number">0</span>生产了 -&gt; Thread-<span class="number">0</span>的第<span class="number">1</span>个产品</span><br><span class="line">Thread-<span class="number">1</span>消费了 -&gt; Thread-<span class="number">0</span>的第<span class="number">1</span>个产品</span><br><span class="line">Thread-<span class="number">2</span>生产了 -&gt; Thread-<span class="number">2</span>的第<span class="number">1</span>个产品</span><br><span class="line">Thread-<span class="number">5</span>消费了 -&gt; Thread-<span class="number">2</span>的第<span class="number">1</span>个产品</span><br><span class="line">Thread-<span class="number">6</span>生产了 -&gt; Thread-<span class="number">6</span>的第<span class="number">1</span>个产品</span><br><span class="line">Thread-<span class="number">1</span>消费了 -&gt; Thread-<span class="number">6</span>的第<span class="number">1</span>个产品</span><br></pre></td></tr></table></figure></p>
<p>发现控制台只打印了几句话就不动了！为什么呢？因为发生死锁了。这就是notify方法导致的线程死锁。为了解释清楚这个问题，我们必须要知道java线程中等待池和锁池的概念以及notify和wait方法的一些细节。</p>
<h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><p>首先我们先要知道什么是等待池和锁池。</p>
<h3 id="等待池"><a href="#等待池" class="headerlink" title="等待池"></a>等待池</h3><p>如果在一个线程的执行过程中，执行了<code>锁对象.wait()</code>方法，那么该线程就会先释放该锁对象，然后进入<code>以该锁对象为标识的等待池</code>。此时该线程就不会再去竞争一切资源，包括CPU的执行权和该锁的持有权。如果没有别的线程执行<code>锁对象.notify()</code>方法，那么这个线程就会一直在等待池中等待下去。当然，即使有别的线程执行<code>锁对象.notify()</code>方法，该线程也未必会从等待池中移除，因为<code>锁对象.notify()</code>只会随机的将该锁对象的等待池中的一个线程唤醒。</p>
<h3 id="锁池"><a href="#锁池" class="headerlink" title="锁池"></a>锁池</h3><p>假设一个线程用了了某个锁对象，当这个线程想要进入<code>synchronized(该锁对象)</code>代码块时，如果此时有其他线程正在同样以该锁对象的同步代码块中执行时，那么本线程只能等待别的线程从代码块中执行完成。在这个期间，本线程就会进入该锁对象为标识的锁池中等待竞争锁。</p>
<h3 id="notify-导致死锁的原因"><a href="#notify-导致死锁的原因" class="headerlink" title="notify()导致死锁的原因"></a>notify()导致死锁的原因</h3><p>为了便于讲清楚造成死锁的原因，我们假设main方法一共开启了1个生产者(称为P1)，2个消费者(C1、C2)，我们假设程序的运行时序是如下的流程：</p>
<ol>
<li>最初C1、C2依次获得了CPU执行权，发现产品为null，所以C1、C2都进入了等待池</li>
<li>然后P1得到CPU执行权，发现产品为null，开始生产产品，生产完之后调用<code>NoneQueue.this.notify()</code>来唤醒等待池中的线程。假设C1被唤醒，由于此时P1还在同步代码块中执行，所以C1进入锁池。</li>
<li>由于while(true)，所以P1再次进入同步代码块(C1虽然在锁池竞争锁，但此时如果P1的CPU执行时间片还没用完，P1有可能再次进入同步代码块的)，P1发现产品不为null，所以执行<code>NoneQueue.this.wait()</code>进入等待池。</li>
<li>在锁池中的C1终于拿到了CPU执行权，消费完成之后，将产品设置为null，并执行<code>NoneQueue.this.notify()</code>方法唤醒等待池中的线程。注意，此时等待池中有C2和P1两个线程，notify方法只会随机唤醒其中一个，假设唤醒的是C2。</li>
<li>唤醒C2后，C2进入锁池竞争锁。由于while(true)，所以当C1再次进入同步代码块时，发现产品为null，所以C1执行<code>NoneQueue.this.wait()</code>进入等待池。</li>
<li>此时，C2拿到CPU执行权，开始进入同步代码块。C2发现产品为null，所以C2执行<code>NoneQueue.this.wait()</code>进入等待池。</li>
<li>这下好了，三个线程全部进入了该锁对象的等待池，没有任何一个线程去唤醒他们，那么程序就卡死在这里形成死锁。</li>
</ol>
<h3 id="解决死锁的办法"><a href="#解决死锁的办法" class="headerlink" title="解决死锁的办法"></a>解决死锁的办法</h3><p>通过上面的程序时序执行分析，我们可以看到，形成死锁的关键原因在于第4步，如果第4步唤醒的是P1，那么就不会出现死锁。但<code>锁对象.notify()</code>方法只能随机唤醒一个等待池中的线程，我们无法控制他到底唤醒哪个，所以这时候就得执行<code>锁对象.notifyAll()</code>方法，这个方法会唤醒所有以该锁对象为标识的等待池中的线程。被唤醒的线程从等待池转入锁池，等待着CPU执行权和锁的持有权，这样就不会出现由上述原因造成的死锁。</p>
<h1 id="基于阻塞队列的多生产者-多消费者模型"><a href="#基于阻塞队列的多生产者-多消费者模型" class="headerlink" title="基于阻塞队列的多生产者-多消费者模型"></a>基于阻塞队列的多生产者-多消费者模型</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HasQueue</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 存放产品的阻塞队列</span></span><br><span class="line">    <span class="keyword">private</span> ArrayBlockingQueue&lt;Product&gt; queue;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">HasQueue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        queue = <span class="keyword">new</span> ArrayBlockingQueue&lt;Product&gt;(<span class="number">10</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//产品类</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Product</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String name;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">Product</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.name = name;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> name;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//生产者</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Producer</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> num = <span class="number">1</span>;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">100</span>);</span><br><span class="line">                    String name = Thread.currentThread().getName() + <span class="string">"的第"</span> + num + <span class="string">"个产品"</span>;</span><br><span class="line">                    <span class="comment">// put方法会向队列插入一个元素，如果队列满了则会被阻塞</span></span><br><span class="line">                    queue.put(<span class="keyword">new</span> Product(name));</span><br><span class="line">                    System.out.println(Thread.currentThread().getName() + <span class="string">"生产了 -&gt; "</span> + name);</span><br><span class="line">                    num++;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//消费者</span></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">Consumer</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">100</span>);</span><br><span class="line">                    <span class="comment">// take方法会从队列取出一个元素，如果队列为空则会被阻塞</span></span><br><span class="line">                    System.out.println(Thread.currentThread().getName() + <span class="string">"消费了 -&gt; "</span> + queue.take().getName());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">        HasQueue demo = <span class="keyword">new</span> HasQueue();</span><br><span class="line">        ExecutorService executorService = Executors.newFixedThreadPool(<span class="number">10</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            executorService.submit(demo.new Producer());</span><br><span class="line">            executorService.submit(demo.new Consumer());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">ygqqq</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">38</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">36</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ygqqq</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.3</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
